---
sidebar_position: 1
tags: ["AI in tendering", "Fraunhofer IAIS", "Machine Learning", "MLOps", "BERT models", "Docker", "GitLab CI/CD", "Stakeholder Involvement", "Production Phase", "Stakeholder Communication", "Model Retraining"]
title: "12. The Fraunhofer Case Study"
---

## summary

- The chapter presents a case study on the innovative use of AI in the tendering process by Fraunhofer IAIS, focusing on automating product matching for a large electronics supplier.
- Fraunhofer IAIS is highlighted as a leading institute in AI, Machine Learning, and Big Data, supporting digital transformation across industries.
- The tendering process involves manual steps like product identification and quotation generation, which the AI system aims to automate.
- Challenges included language hurdles and data understanding, with the project structured into PoC, implementation, and production phases.
- The AI solution uses a pretrained language model for multi-class classification, starting with FastText and moving to BERT-based models for better performance.
- MLOps practices were crucial for the project, emphasizing agile development, containerization with Docker, and continuous integration and deployment.
- The project faced organizational and technical challenges, including data handover and ML solution integration into the company's processes.
- Generative large language models (LLMs) were not used due to constraints like the lack of open-weight models and the need for confidence values in recommendations.
- The case study underscores the importance of integrating business feedback into the agile development of ML solutions.
- The diagram illustrates the IAIS MLOps cycle, emphasizing the integration of development, testing, and production environments.
- Another diagram details the technical architecture supporting the MLOps cycle, highlighting the use of containerization and CI/CD pipelines.
- The project demonstrates the practical application of AI in automating complex, manual processes in the tendering domain.
- The chapter details the implementation phase of the AI solution for tendering, emphasizing stakeholder involvement and the technical architecture.
- Stakeholders from the client side, including decision makers, business unit leads, and IT professionals, were heavily involved in the project, ensuring alignment with business goals.
- The PoC phase focused on developing a minimal viable model using Docker for containerization, which proved successful and led to the implementation phase.
- The implementation phase introduced a full MLOps cycle, with a detailed technical architecture using GitLab for code, Harbour for Docker containers, and MLflow for experiment tracking.
- The project was split into training and deployment pipelines to modularize development, enhance scalability, and facilitate version control.
- The training pipeline included security tests, unit tests, linting, model training, and evaluation, ensuring trackable and reproducible experiments.
- The deployment pipeline focused on packaging the model into a Docker image, conducting security tests, unit tests, linting, and comprehensive application testing before deployment.
- Docker-based virtualization was crucial for the project, providing portability, scalability, and simplified dependency management.
- The chapter highlights the importance of separating training and deployment pipelines to allow for faster iteration and deployment of improvements.
- The diagram illustrates the training pipeline, emphasizing the steps from code management to model evaluation and selection.
- Another diagram details the deployment pipeline, showcasing the process from code evaluation to application deployment in the production environment.
- The case study underscores the practical application of MLOps practices in automating and improving the tendering process through AI.
- The chapter concludes the case study by detailing the production phase, where the ML application was operationalized, emphasizing the importance of continuous communication and model retraining to adapt to real-world changes.
- A BERT-based pretrained language model was utilized in the main project, significantly improving performance over the PoC's simpler model, with additional rules and heuristics ensuring production readiness.
- The implementation phase successfully integrated the model into the customer's systems, achieving a micro-F1 score of 0.49 and an accuracy score of 0.71, meeting the client's success criteria.
- During the production phase, feedback from employees highlighted the model's tendency to make recommendations when no suitable products were available, leading to further model improvements.
- The case study underscores the iterative nature of the MLOps approach, from PoC through implementation to production, ensuring continuous improvement and adaptation to business needs.
- Key takeaways include the necessity of client engagement throughout the project, the value of iterative model testing, leveraging emerging research like BERT models, and utilizing existing tools effectively.
- Discussion questions prompt reflection on choosing between small and large language models and addressing observability in ML systems.
- Further reading suggestions are provided for those interested in deepening their understanding of software process improvement, machine learning solutions, and pretrained language models.
- The successful transition from PoC to production highlights the effectiveness of the MLOps cycle in delivering reliable, high-performing AI solutions that provide significant business value.

## code snippets
```
No direct code references found in the chapter.
```
