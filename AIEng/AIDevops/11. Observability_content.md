---
sidebar_position: 1
tags: ["Observability", "Monitorability", "Explainability", "Data Lineage", "SBOM"]
title: "11. Observability"
---

## summary

- Observability enables AI engineers to detect anomalies, optimize performance, and build trust by understanding system actions through outputs or development processes.
- Related qualities to observability include transparency, monitorability, auditability, and explainability, each with distinct nuances and levels of abstraction.
- Monitorability focuses on tracking predefined metrics in real-time, while observability provides a deeper understanding of system behavior beyond these metrics.
- The evolution from monitorability to observability involves integrating structured data and tracing to correlate events across distributed systems for better insights.
- Observability in AI systems allows for proactive identification of data, model, or concept drift, enhancing system reliability and performance.
- Approaches to enhance observability include recording system activity and tracing data lineage, with architectural mechanisms like monitors and structured logging.
- Data lineage tools and explainability mechanisms like LIME and SHAP are crucial during data preparation and model build for understanding model decisions.
- The system build phase involves constructing a Software Bill of Materials (SBOM) and co-versioning registry to track component versions and their impacts.
- During operations, continuous monitoring, integrating explainability tools, and independent overseeing agents enhance observability and system responsibility.
- The chapter concludes with discussion questions and further reading suggestions to deepen understanding of observability in AI systems.
- Important images include Figure 11.1, illustrating the evolution from monitorability to observability, and descriptions of observability tools and practices.

## code snippets
```
No direct code references found in the chapter.
```
