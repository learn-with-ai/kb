<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-AIEng/AIEngineering/Finetuning_content" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">07. Finetuning | My Site</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://your-docusaurus-site.example.com/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://your-docusaurus-site.example.com/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://your-docusaurus-site.example.com/docs/AIEng/AIEngineering/Finetuning_content"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="07. Finetuning | My Site"><meta data-rh="true" name="description" content="summary"><meta data-rh="true" property="og:description" content="summary"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://your-docusaurus-site.example.com/docs/AIEng/AIEngineering/Finetuning_content"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/docs/AIEng/AIEngineering/Finetuning_content" hreflang="en"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/docs/AIEng/AIEngineering/Finetuning_content" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="My Site RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="My Site Atom Feed"><link rel="stylesheet" href="/assets/css/styles.1724a0b2.css">
<script src="/assets/js/runtime~main.2d8c9eb9.js" defer="defer"></script>
<script src="/assets/js/main.ed51d313.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">My Site</b></a><a class="navbar__item navbar__link" href="/docs/SE/ModelDriven/Part1_">Tutorial</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/AIEng/AIDevops/Introduction_content">AI Engineering Docs</a><a class="navbar__item navbar__link" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/tags">Tags</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/AIEng/AIDevops/Introduction_content">AIDevops</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/AIEng/AIEngineering/Introduction to Building AI Applications with Foundation Models_content">AIEngineering</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/AIEngineering/Introduction to Building AI Applications with Foundation Models_content">01. Introduction to Building AI Applications with Foundation Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/AIEngineering/Understanding Foundation Models _content">02. Understanding Foundation Models </a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/AIEngineering/Evaluation Methodology_content">03. Evaluation Methodology</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/AIEngineering/Evaluate AI Systems _content">04. Evaluate AI Systems </a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/AIEngineering/Prompt Engineering_content">05. Prompt Engineering</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/AIEngineering/RAG and Agents_content">06. RAG and Agents</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/AIEng/AIEngineering/Finetuning_content">07. Finetuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/AIEngineering/Dataset Engineering_content">08. Dataset Engineering</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/AIEngineering/Inference Optimization_content">09. Inference Optimization</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/AIEngineering/Architecture and User Feedback_content">10. Architecture and User Feedback</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/AIEng/LangChain/00Preface_content">LangChain</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/AIEng/PromptEng/The Five Principles of Prompting_content">PromptEng</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/AIEng/ScalableAI/Introduction to Scalable AI Systems_content">ScalableAI</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">AIEngineering</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">07. Finetuning</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>07. Finetuning</h1></header><h2 class="anchor anchorWithStickyNavbar_LWe7" id="summary">summary<a href="#summary" class="hash-link" aria-label="Direct link to summary" title="Direct link to summary">​</a></h2>
<ul>
<li>Finetuning is the process of adapting a model to a specific task by further training the whole model or part of the model, adjusting its weights to enhance various aspects such as domain-specific capabilities, safety, and instruction-following ability.</li>
<li>Compared to prompt-based methods, finetuning requires more up-front investment and incurs a higher memory footprint, making it expensive and challenging, especially with today’s foundation models.</li>
<li>PEFT (parameter-efficient finetuning) is a memory-efficient approach that has become dominant in the finetuning space, differing from traditional finetuning by focusing on reducing memory requirements.</li>
<li>Finetuning brings you into the realm of model training where ML knowledge is required, contrasting with prompt-based methods where such knowledge is recommended but not strictly necessary.</li>
<li>Transfer learning, a concept introduced by Bozinovski and Fulgosi in 1976, is foundational to finetuning, allowing knowledge from one task to accelerate learning for a new, related task.</li>
<li>Finetuning can be done by both model developers and application developers, with model developers typically post-training a model before release and application developers finetuning pre-trained models for specific tasks.</li>
<li>The chapter discusses when to finetune, highlighting that finetuning is generally attempted after extensive experiments with prompt-based methods due to its resource-intensive nature.</li>
<li>Reasons to finetune include improving a model’s quality, enhancing its ability to generate outputs following specific structures, and mitigating biases.</li>
<li>Reasons not to finetune include the potential degradation of a model’s performance for other tasks, the high up-front investments required, and the availability of alternative methods like carefully crafted prompts.</li>
<li>The chapter also covers finetuning domain-specific tasks, noting that general-purpose models are becoming more capable and can outperform domain-specific models in many cases.</li>
<li>An image described in the book illustrates a finetuning process for training large language models, specifically focusing on &quot;Infilling code&quot; using Llama2 Foundation Models with different sizes, serving as an educational tool within the chapter.</li>
<li>Prompt caching is introduced as a method to reuse repetitive prompt segments, though the number of examples usable with a prompt is limited by the maximum context length, unlike finetuning which has no such limit.</li>
<li>The chapter discusses the decision between using RAG or finetuning based on whether the model&#x27;s failures are information-based or behavior-based, with RAG being more effective for information-based failures and finetuning for behavioral issues.</li>
<li>A study by Ovadia et al. (2024) is mentioned, showing RAG&#x27;s superiority over finetuning for tasks requiring up-to-date information, such as questions about current events, and how finetuning can enhance a model&#x27;s performance on specific tasks but may degrade performance in other areas.</li>
<li>The chapter provides a detailed workflow for adapting a model to a task, starting with prompting, adding examples, implementing RAG for information-based failures, and considering finetuning for behavioral issues, with evaluation being a continuous process throughout.</li>
<li>Memory bottlenecks in finetuning are highlighted as a significant challenge, with techniques to minimize memory footprint discussed, including parameter-efficient finetuning (PEFT) and quantization.</li>
<li>The importance of understanding memory requirements for both inference and training is emphasized, with formulas provided for approximate calculations to help in hardware selection.</li>
<li>Backpropagation is explained as the mechanism behind neural network training, detailing the forward and backward passes and how gradients and optimizer states contribute to memory usage during training.</li>
<li>The chapter concludes with practical advice on reducing memory needed for activations through gradient checkpointing or activation recomputation, despite the trade-off of increased training time.</li>
<li>Key images include a flowchart for finetuning within an AI engineering context, a diagram illustrating forward and backward passes in a neural network, and a chart comparing memory usage for different stages of model fine-tuning across various hardware configurations.</li>
<li>The chapter discusses the impact of numerical representations on a model&#x27;s memory footprint, highlighting common floating point formats like FP32, FP16, and BF16, and their trade-offs between range and precision.</li>
<li>Quantization is introduced as a method to reduce memory usage by lowering the precision of numerical values, with practical considerations on what and when to quantize.</li>
<li>The text explains the benefits and challenges of reduced precision, including improved computation speed but potential performance degradation due to value changes.</li>
<li>Inference in lower precision has become standard, with major ML frameworks offering post-training quantization (PTQ) for free.</li>
<li>Training quantization, including quantization-aware training (QAT) and training directly in lower precision, is discussed as a way to reduce training time and cost.</li>
<li>Parameter-Efficient Finetuning (PEFT) techniques are highlighted as a solution to achieve performance close to full finetuning with significantly fewer trainable parameters.</li>
<li>The chapter includes a discussion on model merging as a complementary approach to finetuning, combining multiple models for tailored applications.</li>
<li>Practical implementation opportunities are flagged, such as using quantization to fit models on consumer GPUs and employing PEFT techniques for memory-efficient finetuning.</li>
<li>The text mentions the importance of loading models in their intended numerical format to avoid performance degradation, citing the example of Llama 2.</li>
<li>Interesting insights include the introduction of BitNet b1.58, a 1.58-bit per parameter model, and the performance comparison between different numerical formats.</li>
<li>The chapter concludes with a note on the active research area of reducing precision with minimal impact on model performance and the standard practice of training in higher precision for inference in lower precision.</li>
<li>Important images mentioned include diagrams of different numerical formats with their range and precision bits, and illustrations of adapter modules in transformer blocks for PEFT.</li>
<li>Parameter-Efficient Fine-Tuning (PEFT) methods, including adapter-based and soft prompt-based techniques, enable finetuning models with significantly fewer parameters and data, making it accessible on more affordable hardware.</li>
<li>Adapter-based methods, like LoRA, add trainable parameters to the model without introducing extra inference latency by merging additional modules back into the original layers.</li>
<li>LoRA (Low-Rank Adaptation) decomposes weight matrices into smaller matrices, updating only these during finetuning, which is both parameter and sample efficient.</li>
<li>Soft prompt-based methods modify model input processing by introducing trainable tokens that guide model behavior, differing from hard prompts by being continuous and trainable.</li>
<li>LoRA&#x27;s popularity is highlighted by its dominance in usage among PEFT methods, as evidenced by GitHub issue analysis, due to its efficiency and effectiveness.</li>
<li>The chapter discusses the configuration of LoRA, including decisions on which weight matrices to apply it to and the rank of factorization, impacting performance and memory usage.</li>
<li>Multi-LoRA serving strategies are explored, comparing the trade-offs between merging LoRA weights before serving versus keeping them separate to reduce storage needs and facilitate model switching.</li>
<li>The potential of low-rank pre-training is considered, with recent attempts showing promise but indicating that full-rank pre-training may still be necessary to sufficiently reduce a model&#x27;s intrinsic dimension.</li>
<li>Practical implementation opportunities include experimenting with LoRA configurations for specific tasks and utilizing multi-LoRA serving for efficient model deployment across different use cases.</li>
<li>Interesting insights include the observation that larger models tend to have lower intrinsic dimensions after pre-training, making them easier to finetune with fewer parameters and data.</li>
<li>The chapter concludes with a look towards future developments in low-rank pre-training and the ongoing exploration of PEFT methods for model finetuning.</li>
<li>Important images mentioned include visualizations of LoRA&#x27;s application to weight matrices, the combination of hard and soft prompts, and the popularity of different PEFT methods based on GitHub issue analysis.</li>
<li>LoRA adapters reduce the memory footprint of base models and can be shared and reused, available on platforms like Hugging Face and AdapterHub.</li>
<li>LoRA&#x27;s main drawback is its performance compared to full finetuning and the complexity involved in modifying the model&#x27;s implementation.</li>
<li>Quantized LoRA, like QLoRA, stores model weights in 4 bits, significantly reducing memory usage and enabling finetuning of large models on single GPUs.</li>
<li>Model merging combines multiple models to create a new, more useful model, offering flexibility and reduced memory footprint, especially for on-device deployment.</li>
<li>Multi-task finetuning can be approached through simultaneous or sequential finetuning, with model merging offering a method to avoid catastrophic forgetting.</li>
<li>Model merging is essential for federated learning, allowing the combination of models trained on different devices into a single base model.</li>
<li>Ensembling combines model outputs for better performance but at a higher inference cost compared to model merging.</li>
<li>Model merging techniques include summing, layer stacking, and concatenation, with summing further divided into linear combination and spherical linear interpolation (SLERP).</li>
<li>Pruning redundant task-specific parameters before merging can significantly improve the quality of the final merged models.</li>
<li>The chapter highlights practical steps for finetuning and model merging, including the use of specific frameworks and techniques for optimal performance.</li>
<li>Images in the chapter illustrate concepts like ensembling vs. model merging, different model merging approaches, and the impact of pruning on model performance.</li>
<li>Layer stacking, or frankenmerging, involves combining layers from different models to create unique architectures, requiring further finetuning for optimal performance.</li>
<li>Goliath-120B is an example of successful frankenmerging, created from two finetuned Llama 2-70B models.</li>
<li>Layer stacking can train Mixture-of-Experts (MoE) models by copying pre-trained model layers and adding a router for input distribution.</li>
<li>Komatsuzaki et al. demonstrated that layer stacking can outperform MoE models trained from scratch, as seen with Together AI&#x27;s Mixture-of-Agents.</li>
<li>Model upscaling via layer stacking allows creating larger models from existing ones without training from scratch, optimizing resource use.</li>
<li>Depthwise scaling is a technique for model upscaling, exemplified by the creation of SOLAR 10.7B from a 7B-parameter model.</li>
<li>Concatenation merges model parameters by summing them, though it&#x27;s not recommended due to memory footprint concerns.</li>
<li>Finetuning tactics involve choosing a base model, finetuning method, and framework, with considerations for model size, licenses, and performance.</li>
<li>OpenAI&#x27;s finetuning best practices outline progression and distillation paths for model development.</li>
<li>Adapter techniques like LoRA are cost-effective but may not match full finetuning performance, suitable for small datasets.</li>
<li>Finetuning frameworks such as LLA MA-Factory and PEFT support various finetuning methods, offering flexibility but requiring compute resources.</li>
<li>Hyperparameters like learning rate, batch size, number of epochs, and prompt loss weight are crucial for finetuning efficiency and performance.</li>
<li>The chapter highlights the complexity of finetuning&#x27;s context, including when to finetune versus using RAG, and the challenges of obtaining high-quality data.</li>
<li>Interesting insights include the alignment tax phenomenon and the practical challenges of adopting finetuning in businesses.</li>
<li>Practical steps involve experimenting with hyperparameters and choosing between finetuning methods based on data volume and project needs.</li>
<li>Real-world applications include model upscaling and the creation of specialized models like Mixture-of-Agents.</li>
<li>Additional key insights discuss the evolution of finetuning techniques to address memory and resource constraints.</li>
<li>Final takeaway emphasizes the balance between finetuning&#x27;s ease of implementation and the complexity of its surrounding context.</li>
<li>Important images include diagrams illustrating the process of creating MoE models from pre-trained models and the depthwise scaling technique.</li>
<li>The chapter discusses various finetuning techniques and memory optimization strategies in AI, including the use of surrogate gradients and direct feedback alignment for updating model weights.</li>
<li>It highlights the importance of understanding model architecture for effectively using LoRA and mentions constraints in some finetuning frameworks due to hardware memory limitations.</li>
<li>The text explores the confusion between FP16 and BF16 formats and the significance of designing numerical formats that do not compromise system quality.</li>
<li>Personal anecdotes and references to external resources like Carol Chen’s “Transformer Inference Arithmetic” and EleutherAI’s “Transformer Math 101” are provided for deeper understanding.</li>
<li>The chapter also touches on partial finetuning, emphasizing the finetuning of layers closest to the output layer for task-specific adjustments.</li>
<li>Mentions of quantized LoRA works and the acquisition of Xnor.ai by Apple underscore the practical and commercial aspects of model compression technologies.</li>
<li>The narrative includes a personal story about the pitfalls of model training, such as losing progress due to incorrect checkpoint saving.</li>
<li>It concludes with a note on the magical effectiveness of simple components in AI, like averaging embeddings, and the ongoing challenges in understanding training stability with small batch sizes.</li>
<li>Important images or descriptions mentioned in the book include references to external blogs and papers for further reading on inference and training memory calculations.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="code-snippets">code snippets<a href="#code-snippets" class="hash-link" aria-label="Direct link to code snippets" title="Direct link to code snippets">​</a></h2>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">No direct code references found in the chapter.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-tags-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/finetuning">Finetuning</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/peft-parameter-efficient-finetuning">PEFT (Parameter-Efficient Finetuning)</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/transfer-learning">Transfer Learning</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/ll-ms-large-language-models">LLMs (Large Language Models)</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/adapter-based-techniques">Adapter-based Techniques</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/rag-retrieval-augmented-generation">RAG (Retrieval-Augmented Generation)</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/prompt-caching">Prompt Caching</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/memory-bottlenecks">Memory Bottlenecks</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/backpropagation">Backpropagation</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/fp-32">FP32</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/fp-16">FP16</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/bf-16">BF16</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/quantization">Quantization</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/parameter-efficient-finetuning-peft">Parameter-Efficient Finetuning (PEFT)</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/lo-ra">LoRA</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/peft">PEFT</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/adapter-based-methods">Adapter-based methods</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/soft-prompt-based-methods">Soft prompt-based methods</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/low-rank-factorization">Low-rank factorization</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/q-lo-ra">QLoRA</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/model-merging">Model Merging</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/federated-learning">Federated Learning</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/layer-stacking">Layer stacking</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/mixture-of-experts-mo-e">Mixture-of-Experts (MoE)</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/hyperparameter-tuning">Hyperparameter tuning</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/b-float-16">BFloat16</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/mixed-precision-training">Mixed Precision Training</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/transformer-based-models">Transformer-based models</a></li></ul></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/AIEng/AIEngineering/RAG and Agents_content"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">06. RAG and Agents</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/AIEng/AIEngineering/Dataset Engineering_content"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">08. Dataset Engineering</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#summary" class="table-of-contents__link toc-highlight">summary</a></li><li><a href="#code-snippets" class="table-of-contents__link toc-highlight">code snippets</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Tutorial</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://x.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/learn-with-ai/kb" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>