<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-AIEng/ScalableAI/Fundamentals of Scalability in AI_content" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">02. Fundamentals of Scalability in AI | My Site</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://your-docusaurus-site.example.com/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://your-docusaurus-site.example.com/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://your-docusaurus-site.example.com/docs/AIEng/ScalableAI/Fundamentals of Scalability in AI_content"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="02. Fundamentals of Scalability in AI | My Site"><meta data-rh="true" name="description" content="summary"><meta data-rh="true" property="og:description" content="summary"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://your-docusaurus-site.example.com/docs/AIEng/ScalableAI/Fundamentals of Scalability in AI_content"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/docs/AIEng/ScalableAI/Fundamentals of Scalability in AI_content" hreflang="en"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/docs/AIEng/ScalableAI/Fundamentals of Scalability in AI_content" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="My Site RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="My Site Atom Feed"><link rel="stylesheet" href="/assets/css/styles.1724a0b2.css">
<script src="/assets/js/runtime~main.2d8c9eb9.js" defer="defer"></script>
<script src="/assets/js/main.ed51d313.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">My Site</b></a><a class="navbar__item navbar__link" href="/docs/SE/ModelDriven/Part1_">Tutorial</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/AIEng/AIDevops/Introduction_content">AI Engineering Docs</a><a class="navbar__item navbar__link" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/tags">Tags</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/AIEng/AIDevops/Introduction_content">AIDevops</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/AIEng/AIEngineering/Introduction to Building AI Applications with Foundation Models_content">AIEngineering</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/AIEng/LangChain/00Preface_content">LangChain</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/AIEng/PromptEng/The Five Principles of Prompting_content">PromptEng</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/AIEng/ScalableAI/Introduction to Scalable AI Systems_content">ScalableAI</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/ScalableAI/Introduction to Scalable AI Systems_content">01. Introduction to Scalable AI Systems</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/AIEng/ScalableAI/Fundamentals of Scalability in AI_content">02. Fundamentals of Scalability in AI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/ScalableAI/Data Engineering for Scalable AI_content">03. Data Engineering for Scalable AI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/ScalableAI/Scalable AI Algorithms and Models_content">04. Scalable AI Algorithms and Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/ScalableAI/Scalable AI Infrastructure and Architecture_content">05. Scalable AI Infrastructure and Architecture</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/ScalableAI/Scalable AI Deployment and Productionization_content">06. Scalable AI Deployment and Productionization</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/ScalableAI/Scalable AI for Real-Time and Streaming Data_content">07. Scalable AI for Real-Time and Streaming Data</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/ScalableAI/Scalable AI for Edge Computing_content">08. Scalable AI for Edge Computing</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/ScalableAI/Scalable AI Governance and Ethics_content">09. Scalable AI Governance and Ethics</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/ScalableAI/Case Studies and Best Practices_content">10. Case Studies and Best Practices</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/ScalableAI/Future Trends and Emerging Technologies_content">11. Future Trends and Emerging Technologies</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/ScalableAI/Conclusion and Final Thoughts_content">12. Conclusion and Final Thoughts</a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">ScalableAI</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">02. Fundamentals of Scalability in AI</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>02. Fundamentals of Scalability in AI</h1></header><h2 class="anchor anchorWithStickyNavbar_LWe7" id="summary">summary<a href="#summary" class="hash-link" aria-label="Direct link to summary" title="Direct link to summary">​</a></h2>
<ul>
<li>Scalability in AI is compared to scaling up a cookie recipe for a large party without losing quality, emphasizing the need for systems to handle more data, users, or complex tasks efficiently.</li>
<li>Handling large datasets is crucial for AI applications, with techniques like data sampling, preprocessing, streaming, parallel processing, distributed computing, and data indexing being essential for effective management.</li>
<li>Data sampling involves selecting a representative subset of data for analysis, similar to tasting a small portion of soup to judge its overall flavor.</li>
<li>Data preprocessing and cleaning are likened to tidying a cluttered space before work, ensuring data is ready for analysis by addressing noise, missing values, or discrepancies.</li>
<li>Data streaming processes data in manageable portions rather than loading entire datasets into memory, akin to reading a book one chapter at a time.</li>
<li>Parallel processing divides tasks into smaller parts processed simultaneously, enhancing efficiency, similar to multiple chefs working on different parts of a meal.</li>
<li>Distributed computing distributes tasks across multiple machines, speeding up processes and increasing scalability, comparable to using multiple ovens to bake cookies faster.</li>
<li>Dask is highlighted as a Python library for parallel and distributed computing, capable of handling larger-than-memory datasets efficiently.</li>
<li>Model partitioning in scalable AI systems distributes computational workloads across multiple devices, crucial for large-scale models that exceed single machine memory.</li>
<li>Distributed computing frameworks like Ray and Dask facilitate parallel and distributed computing tasks, supporting applications from reinforcement learning to big data analytics.</li>
<li>Distributed Artificial Intelligence (DAI) distributes AI tasks across multiple nodes, enhancing scalability, fault tolerance, and resource utilization.</li>
<li>Techniques for distributed computing include parallelism, distributed databases, and message queues, each contributing to efficient data processing and task management.</li>
<li>Use cases for distributed computing span NLP, image and video editing, recommendation engines, and internet search engines, demonstrating its broad applicability.</li>
<li>A practical example of distributed computing in action is a distributed sentiment analysis system for real-time tweet analysis, showcasing scalability and efficiency.</li>
<li>Parallel processing techniques enable AI models to handle larger workloads more efficiently by dividing tasks into smaller, concurrently processed sections.</li>
<li>The importance of parallel processing in AI is illustrated with the analogy of grading arithmetic papers, where dividing the task among multiple graders speeds up completion.</li>
<li>The diagram overview emphasizes how large-scale projects can be managed through parallelism, distributed databases, and efficient handling of user queries, highlighting scalability&#x27;s role in AI.</li>
<li>Parallel processing in AI is likened to having multiple chefs work on different parts of a meal simultaneously, enhancing task speed, scalability, and resource efficiency.</li>
<li>Data parallelism involves dividing datasets into smaller chunks for parallel processing, demonstrated through Python&#x27;s multiprocessing package.</li>
<li>Model parallelism allows large AI models to be distributed across multiple GPUs or machines, with frameworks like TensorFlow and PyTorch facilitating this distribution.</li>
<li>Task parallelism breaks down large tasks into smaller subtasks processed concurrently, utilizing libraries such as Celery for distributed task processing.</li>
<li>Challenges in parallel processing include synchronization issues, load distribution imbalances, and communication overhead, which can affect efficiency and performance.</li>
<li>Scaling AI models involves making them more powerful and capable of handling complex tasks, akin to upgrading from a simple laptop to a supercomputer.</li>
<li>Key reasons for scaling AI models include handling complex tasks, improving accuracy, increasing efficiency, and enhancing adaptability for specific tasks.</li>
<li>Techniques for scaling AI models include adopting larger model architectures like GPT-3, implementing parallel processing, utilizing distributed computing, and applying quantization to reduce computational needs.</li>
<li>Balancing processing resources, data handling, and optimization is crucial for maximizing the potential of scaled AI models across various domains.</li>
<li>The chapter concludes by summarizing the importance of scalability in AI, highlighting efficient data handling techniques, the role of distributed computing, and the benefits and challenges of parallel processing and model scaling.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="code-snippets">code snippets<a href="#code-snippets" class="hash-link" aria-label="Direct link to code snippets" title="Direct link to code snippets">​</a></h2>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import pandas as pd</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Load a large dataset</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">data = pd.read_csv(&#x27;large_dataset.csv&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Randomly sample 10% of the data</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sampled_data = data.sample(frac=0.1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from PIL import Image</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Clean and preprocess a directory of images</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def preprocess_images(input_dir, output_dir, target_size=(224, 224)):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for filename in os.listdir(input_dir):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        img = Image.open(os.path.join(input_dir, filename))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        img = img.resize(target_size)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        img.save(os.path.join(output_dir, filename))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Usage</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">preprocess_images(&#x27;input_images&#x27;, &#x27;output_images&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Process data from a file in chunks</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chunk_size = 1000</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">with open(&#x27;large_file.txt&#x27;, &#x27;r&#x27;) as file:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    while True:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        data_chunk = file.read(chunk_size)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if not data_chunk:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            break</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Process the chunk</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from multiprocessing import Pool</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Define a function to process data</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def process_data(data_chunk):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Process the data_chunk here</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Split the dataset</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">data_chunks = split_large_dataset(large_data)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Create a pool of worker processes</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">with Pool(processes=4) as pool:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    results = pool.map(process_data, data_chunks)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from dask import dataframe as dd</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Load a large dataset with Dask</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">data = dd.read_csv(&#x27;large_dataset.csv&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Perform operations on the distributed dataframe</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">result = data.groupby(&#x27;category&#x27;).mean().compute()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import pandas as pd</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Load a large dataset</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">data = pd.read_csv(&#x27;large_dataset.csv&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Create an index based on a column (e.g., customer_id)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">data_indexed = data.set_index(&#x27;customer_id&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Retrieve data by customer_id quickly</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">specific_data = data_indexed.loc[&#x27;12345&#x27;]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from multiprocessing import Pool</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Define a function to count words</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def count_word(word, text):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return text.count(word)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Split the text into smaller chunks</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">text = &quot;This is a big book with many words...&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chunks = [text[i:i+10] for i in range(0, len(text), 10)]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Create a pool of workers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">with Pool(10) as p:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Use parallelism to count the word in each chunk</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    counts = p.starmap(count_word, [(&quot;cat&quot;, chunk) for chunk in chunks])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Sum up the counts from each chunk</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">total_count = sum(counts)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(total_count)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from celery import Celery</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Initialize a Celery worker</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">app = Celery(&#x27;myapp&#x27;, broker=&#x27;pyamqp://guest@localhost//&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Define a task to process messages</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@app.task</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def process_message(message):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Process the message here</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return &quot;Processed: &quot; + message</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Send a message to the queue</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">message = &quot;How can I reset my password?&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">result = process_message.apply_async(args=[message])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(result.get())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import multiprocessing</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def process_data(chunk):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Process the data in this chunk</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    pass</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if __name__ == &quot;__main__&quot;:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    data = get_large_dataset()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    num_processors = multiprocessing.cpu_count()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    pool = multiprocessing.Pool(processes=num_processors)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    results = pool.map(process_data, data)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    pool.close()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    pool.join()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import tensorflow as tf</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Build and compile the model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model = create_large_model()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model.compile(optimizer=&#x27;adam&#x27;, loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=[&#x27;accuracy&#x27;])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Split the model across multiple GPUs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">strategy = tf.distribute.MirroredStrategy()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">with strategy.scope():</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    parallel_model = create_parallel_model(model)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Train the model in parallel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">parallel_model.fit(train_data, epochs=10)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from celery import Celery</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">app = Celery(&#x27;myapp&#x27;, broker=&#x27;pyamqp://guest@localhost//&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@app.task</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def process_task(task_data):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Process the task</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    pass</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Create and distribute tasks</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">for task_data in large_task_list:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    process_task.delay(task_data)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-tags-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/scalability">Scalability</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/large-datasets">Large Datasets</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/distributed-computing">Distributed Computing</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/parallel-processing">Parallel Processing</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/data-preprocessing">Data Preprocessing</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/model-architectures">Model Architectures</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/quantization">Quantization</a></li></ul></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/AIEng/ScalableAI/Introduction to Scalable AI Systems_content"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">01. Introduction to Scalable AI Systems</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/AIEng/ScalableAI/Data Engineering for Scalable AI_content"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">03. Data Engineering for Scalable AI</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#summary" class="table-of-contents__link toc-highlight">summary</a></li><li><a href="#code-snippets" class="table-of-contents__link toc-highlight">code snippets</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Tutorial</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://x.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/learn-with-ai/kb" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>