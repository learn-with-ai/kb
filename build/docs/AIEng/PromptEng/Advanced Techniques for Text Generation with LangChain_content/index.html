<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-AIEng/PromptEng/Advanced Techniques for Text Generation with LangChain_content" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">04. Advanced Techniques for Text Generation with LangChain | My Site</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://your-docusaurus-site.example.com/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://your-docusaurus-site.example.com/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://your-docusaurus-site.example.com/docs/AIEng/PromptEng/Advanced Techniques for Text Generation with LangChain_content"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="04. Advanced Techniques for Text Generation with LangChain | My Site"><meta data-rh="true" name="description" content="titles"><meta data-rh="true" property="og:description" content="titles"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://your-docusaurus-site.example.com/docs/AIEng/PromptEng/Advanced Techniques for Text Generation with LangChain_content"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/docs/AIEng/PromptEng/Advanced Techniques for Text Generation with LangChain_content" hreflang="en"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/docs/AIEng/PromptEng/Advanced Techniques for Text Generation with LangChain_content" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="My Site RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="My Site Atom Feed"><link rel="stylesheet" href="/assets/css/styles.1724a0b2.css">
<script src="/assets/js/runtime~main.2d8c9eb9.js" defer="defer"></script>
<script src="/assets/js/main.ed51d313.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">My Site</b></a><a class="navbar__item navbar__link" href="/docs/SE/ModelDriven/Part1_">Tutorial</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/AIEng/AIDevops/Introduction_content">AI Engineering Docs</a><a class="navbar__item navbar__link" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/tags">Tags</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/AIEng/AIDevops/Introduction_content">AIDevops</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/AIEng/AIEngineering/Introduction to Building AI Applications with Foundation Models_content">AIEngineering</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/AIEng/LangChain/00Preface_content">LangChain</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/AIEng/PromptEng/The Five Principles of Prompting_content">PromptEng</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/PromptEng/The Five Principles of Prompting_content">01. The Five Principles of Prompting</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/PromptEng/Introduction to Large Language Models for Text Generation_content">02. Introduction to Large Language Models for Text Generation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/PromptEng/Standard Practices for Text Generation with ChatGPT_content">03. Standard Practices for Text Generation with ChatGPT</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/AIEng/PromptEng/Advanced Techniques for Text Generation with LangChain_content">04. Advanced Techniques for Text Generation with LangChain</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/PromptEng/Vector Databases with FAISS and Pinecone_content">05. Vector Databases with FAISS and Pinecone</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/PromptEng/Autonomous Agents with Memory and Tools_content">06. Autonomous Agents with Memory and Tools</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/PromptEng/Introduction to Diffusion Models for Image Generation_content">07. Introduction to Diffusion Models for Image Generation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/PromptEng/Standard Practices for Image Generation with Midjourney_content">08. Standard Practices for Image Generation with Midjourney</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/PromptEng/Advanced Techniques for Image Generation with Stable Diffusion_content">09. Advanced Techniques for Image Generation with Stable Diffusion</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/PromptEng/Building AI-Powered Applications_content">10. Building AI-Powered Applications</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/AIEng/ScalableAI/Introduction to Scalable AI Systems_content">ScalableAI</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">PromptEng</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">04. Advanced Techniques for Text Generation with LangChain</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>04. Advanced Techniques for Text Generation with LangChain</h1></header><h2 class="anchor anchorWithStickyNavbar_LWe7" id="titles">titles<a href="#titles" class="hash-link" aria-label="Direct link to titles" title="Direct link to titles">​</a></h2>
<p>Advanced Techniques for Text Generation with LangChain Advanced Techniques for Text Generation with LangChain</p>
<p>Output Parsers, Evaluations, and Function Calling Advanced Techniques for Text Generation with LangChain</p>
<p>Function Calling, Query Planning, and Few-Shot Learning Advanced Techniques for Text Generation with LangChain</p>
<p>Data Connection, Text Splitters, and Task Decomposition Advanced Techniques for Text Generation with LangChain</p>
<p>Prompt Chaining, Sequential Chains, and Document Chains Advanced Techniques for Text Generation with LangChain</p>
<p>Document Chains and Summarization Strategies</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="summary">summary<a href="#summary" class="hash-link" aria-label="Direct link to summary" title="Direct link to summary">​</a></h2>
<ul>
<li>LangChain is introduced as a versatile framework for creating applications that utilize Large Language Models (LLMs), available in both Python and TypeScript.</li>
<li>The framework enhances data awareness and agency by connecting language models with external data sources and enabling them to interact with their environment.</li>
<li>LangChain&#x27;s modular design includes Model I/O, Retrieval, Chains, Agents, Memory, and Callbacks, each serving distinct functions in LLM workflows.</li>
<li>Practical setup instructions for LangChain include installation via pip or conda, and the importance of using virtual environments and managing API keys securely is highlighted.</li>
<li>Chat models like GPT-4 are discussed, emphasizing the use of message types (AIMessage, HumanMessage, SystemMessage) for generating LLM responses.</li>
<li>A joke generator example demonstrates how to use ChatOpenAI with specific message types to produce tailored outputs.</li>
<li>Streaming chat models are explained, noting their benefits in reducing latency and enhancing user interactivity, alongside the challenges of parsing streaming outputs.</li>
<li>The capability to generate multiple LLM responses for dynamic content creation is showcased, along with the use of asynchronous functions for efficient task performance.</li>
<li>LangChain Prompt Templates are introduced as a method for creating reproducible prompts, offering advantages over simple string formatting like input validation and composition.</li>
<li>LangChain Expression Language (LCEL) is described, highlighting the use of the pipe operator to chain components for complex data processing pipelines.</li>
<li>A business name generator example illustrates the application of prompt templates and LCEL in generating structured outputs.</li>
<li>Output parsers in LangChain are overviewed, including various types like List, Datetime, and Pydantic (JSON) parsers, with a focus on their utility in extracting structured data from LLM responses.</li>
<li>The Pydantic (JSON) parser is detailed for its flexibility and use of Python type annotations for data validation, demonstrated through a business name rating example.</li>
<li>The chapter concludes with practical insights into leveraging LangChain for advanced text generation tasks, emphasizing the framework&#x27;s role in simplifying complex model integrations and enhancing LLM applications.</li>
<li>The chapter delves into advanced techniques for text generation using LangChain, focusing on output parsers, evaluation metrics, and OpenAI function calling.</li>
<li>Output parsers in LangChain, particularly the Pydantic (JSON) parser, are highlighted for their ability to structure LLM outputs into predefined formats, enhancing data retrieval and organization.</li>
<li>A practical example demonstrates using Pydantic models to parse business names and ratings, showcasing the flexibility and utility of output parsers in structuring LLM responses.</li>
<li>LangChain&#x27;s evaluation metrics (evals) are introduced as essential tools for measuring the performance of prompt responses, with examples of using exact string matches and pairwise comparisons for accuracy assessment.</li>
<li>The chapter provides a detailed walkthrough of implementing evaluation metrics with Mistral and GPT-3.5 models, including setting up API keys and processing transaction data for classification.</li>
<li>Advanced evaluators like labeled_pairwise_string are discussed for comparing outputs from different models or prompts, with GPT-4 used to provide reasoning for the comparisons.</li>
<li>OpenAI function calling is presented as an alternative to output parsers, enabling models to generate JSON responses for predefined functions, useful for chatbots, API calls, and data extraction.</li>
<li>A mock function for scheduling meetings illustrates the process of defining function schemas and integrating them with OpenAI models for practical applications.</li>
<li>The importance of detailed JSON schemas in function calling is emphasized to guide models in understanding when and how to invoke functions properly.</li>
<li>The chapter concludes with insights into automating evaluation metrics for faster iteration and improvement of LLM applications, reducing reliance on manual reviews.</li>
<li>The chapter explores advanced techniques in LangChain, including function calling with OpenAI models, query planning, and few-shot learning for text generation.</li>
<li>Function calling is demonstrated with OpenAI models, showing how to schedule meetings by defining functions and their JSON schemas, and handling parallel function calls.</li>
<li>A practical example illustrates parallel function calling to schedule multiple meetings, showcasing the flexibility of AI-powered tools in handling complex requests.</li>
<li>LangChain&#x27;s integration with Pydantic for function calling simplifies structured data extraction from LLM responses, avoiding the need for manual JSON schema writing.</li>
<li>Query planning is introduced as a method to parse user queries into executable steps with dependencies, using Pydantic models to structure the query plan.</li>
<li>Few-shot learning is detailed with examples of creating fixed-length and dynamically selected few-shot prompts to guide LLM responses more effectively.</li>
<li>The use of LengthBasedExampleSelector is highlighted for adapting prompts based on input length, ensuring responses stay within the LLM&#x27;s context window limits.</li>
<li>Limitations of few-shot learning are discussed, including overfitting to examples and token limits, with suggestions for mitigation such as prompt phrasing and fine-tuning.</li>
<li>The chapter concludes with the benefits of saving and loading LLM prompts as files for better shareability, storage, and versioning, supported by LangChain&#x27;s JSON and YAML compatibility.</li>
<li>Practical code examples throughout the chapter demonstrate the implementation of these advanced techniques, providing a hands-on understanding of their application.</li>
<li>The chapter covers advanced techniques in LangChain for text generation, focusing on data connection, text splitters, and task decomposition.</li>
<li>Data connection involves loading, transforming, embedding, and storing unstructured data in vector databases, with LangChain providing components for these processes.</li>
<li>Document loaders in LangChain facilitate the uploading of documents from various sources, including PDFs, Word documents, and web pages, into a cohesive data pipeline.</li>
<li>Text splitters are introduced as tools to break down large chunks of text to fit the model&#x27;s context window, with examples including CharacterTextSplitter, TokenTextSplitter, and RecursiveCharacterTextSplitter.</li>
<li>The importance of balancing document length is highlighted to avoid surpassing the LLM&#x27;s context length or losing significant contextual information.</li>
<li>Task decomposition is presented as a strategy to dissect complex problems into manageable subproblems, enhancing the utility and effectiveness of LLMs in problem-solving scenarios.</li>
<li>Practical examples demonstrate the application of these techniques, such as loading and splitting documents, adding metadata, and using recursive character splitting for large texts.</li>
<li>The chapter concludes with insights into leveraging these advanced techniques to work seamlessly with various document sources and integrate them into robust data pipelines.</li>
<li>Code examples throughout the chapter provide hands-on understanding of implementing these techniques, from document loading and splitting to task decomposition with LLMs.</li>
<li>The chapter explores advanced techniques in LangChain for text generation, focusing on prompt chaining, sequential chains, and document chains to manage complex workflows.</li>
<li>Task decomposition is introduced as a strategy to break down complex problems into manageable subproblems, enhancing the effectiveness of LLMs in various applications like content generation and interactive conversational agents.</li>
<li>Prompt chaining is demonstrated through a film company example, where multiple prompt inputs/outputs are combined to automate film creation components such as character creation, plot generation, and scenes/world building.</li>
<li>Sequential chains are detailed with examples of creating and integrating multiple LLM chains to orchestrate complicated workflows, using RunnablePassthrough, itemgetter, and RunnableParallel for data flow management.</li>
<li>Document chains are highlighted for summarizing large amounts of text that exceed LLM context length restrictions, with practical examples using CharacterTextSplitter and load_summarize_chain for text summarization tasks.</li>
<li>The chapter provides code examples for implementing these techniques, including creating LCEL chains for character, plot, and scene generation, and using Pandas for data manipulation in document summarization.</li>
<li>Key insights include the importance of structuring LCEL chains correctly to avoid errors and the benefits of using different models for ideation and generation within sequential chains.</li>
<li>Practical steps for generating character scripts and summarizing scenes are outlined, showcasing how to maintain narrative continuity and context in generated content.</li>
<li>The chapter concludes with the application of these advanced techniques in real-world scenarios, such as automating film creation and summarizing large documents, demonstrating their versatility and power in text generation tasks.</li>
<li>The chapter delves into advanced techniques for text generation using LangChain, focusing on document chains and summarization strategies to manage large datasets effectively.</li>
<li>Four core document chain strategies are introduced: Stuff, Refine, Map Reduce, and Map Re-rank, each with unique advantages and disadvantages for different scenarios.</li>
<li>The Stuff documents chain is highlighted for its simplicity, ideal for small documents, while the Refine documents chain offers iterative response refinement, beneficial for progressive extraction tasks.</li>
<li>Map Reduce documents chain is detailed for its ability to handle large datasets by processing each document independently and combining results, with an optional compression step for context length management.</li>
<li>Map Re-rank documents chain is noted for providing confidence scores for each answer, allowing for better response selection, though it may require complex ranking algorithms.</li>
<li>Practical implementation tips are provided, including changing the chain type within the load_summarize_chain function to suit different summarization needs.</li>
<li>The chapter concludes by summarizing the importance of document loaders, text splitters, task decomposition, and prompt chaining in enhancing text generation workflows with LangChain.</li>
<li>A preview of the next chapter teases the integration of vector databases with LangChain documents to improve knowledge extraction accuracy from data.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="code-snippets">code snippets<a href="#code-snippets" class="hash-link" aria-label="Direct link to code snippets" title="Direct link to code snippets">​</a></h2>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip install langchain langchain-openai</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">conda install -c conda-forge langchain langchain-openai</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">python -m venv venv</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">source venv/bin/activate</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip install -r requirements.txt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip install openai</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_openai.chat_models import ChatOpenAI</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chat = ChatOpenAI(api_key=&quot;api_key&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.schema import AIMessage, HumanMessage, SystemMessage</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chat = ChatOpenAI(temperature=0.5)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">messages = [SystemMessage(content=&#x27;Act as a senior software engineer at a startup company.&#x27;), HumanMessage(content=&#x27;Please can you provide a funny joke about software engineers?&#x27;)]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">response = chat.invoke(input=messages)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(response.content)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">for chunk in chat.stream(messages): print(chunk.content, end=&quot;&quot;, flush=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">synchronous_llm_result = chat.batch([messages]*2)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_core.runnables.config import RunnableConfig</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">config = RunnableConfig(max_concurrency=5)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">results = chat.batch([messages, messages], config=config)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_core.prompts import (SystemMessagePromptTemplate, ChatPromptTemplate)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">template = &quot;You are a creative consultant brainstorming names for businesses...&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">system_prompt = SystemMessagePromptTemplate.from_template(template)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chat_prompt = ChatPromptTemplate.from_messages([system_prompt])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chain = chat_prompt | model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">result = chain.invoke({&quot;industry&quot;: &quot;medical&quot;, &quot;context&quot;:&quot;creating AI solutions by automatically summarizing patient records&quot;, &quot;principles&quot;:&quot;1. Each name should be short and easy to remember. 2. Each name should be easy to pronounce.&quot;})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_core.prompts import PromptTemplate</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">prompt=PromptTemplate(template=&#x27;You are a helpful assistant that translates {input_language} to {output_language}.&#x27;, input_variables=[&quot;input_language&quot;, &quot;output_language&quot;],)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">system_message_prompt = SystemMessagePromptTemplate(prompt=prompt)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chat.invoke(system_message_prompt.format_messages(input_language=&quot;English&quot;,output_language=&quot;French&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.output_parsers import PydanticOutputParser</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from pydantic.v1 import BaseModel, Field</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from typing import List</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">class BusinessName(BaseModel): name: str = Field(description=&quot;The name of the business&quot;) rating_score: float = Field(description=&#x27;The rating score of the business. 0 is the worst, 10 is the best.&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">class BusinessNames(BaseModel): names: List[BusinessName] = Field(description=&#x27;A list of busines names&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">parser = PydanticOutputParser(pydantic_object=BusinessNames)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model = ChatOpenAI()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">system_message_prompt = SystemMessagePromptTemplate.from_template(template)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">prompt_and_model = chat_prompt | model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">result = prompt_and_model.invoke({&quot;principles&quot;: principles, &quot;industry&quot;: &quot;Data Science&quot;, &quot;format_instructions&quot;: parser.get_format_instructions(),})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(parser.parse(result.content))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chain = prompt | model | output_parser</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chain = chat_prompt | model | parser</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">result = chain.invoke({&quot;principles&quot;: principles, &quot;industry&quot;: &quot;Data Science&quot;, &quot;format_instructions&quot;: parser.get_format_instructions(),})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_mistralai.chat_models import ChatMistralAI</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model = ChatMistralAI(model=&quot;mistral-small&quot;, mistral_api_key=mistral_api_key)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">class EnrichedTransactionInformation(BaseModel): transaction_type: Union[Literal[&quot;Purchase&quot;, &quot;Withdrawal&quot;, &quot;Deposit&quot;, &quot;Bill Payment&quot;, &quot;Refund&quot;], None] transaction_category: Union[Literal[&quot;Food&quot;, &quot;Entertainment&quot;, &quot;Transport&quot;, &quot;Utilities&quot;, &quot;Rent&quot;, &quot;Other&quot;], None,]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">output_parser = PydanticOutputParser(pydantic_object=EnrichedTransactionInformation)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chain = prompt | model | StrOutputParser() | remove_back_slashes | output_parser</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.evaluation import load_evaluator</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">evaluator = load_evaluator(&quot;labeled_pairwise_string&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from openai import OpenAI</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def schedule_meeting(date, time, attendees): return { &quot;event_id&quot;: &quot;1234&quot;, &quot;status&quot;: &quot;Meeting scheduled successfully&quot;, &quot;date&quot;: date, &quot;time&quot;: time, &quot;attendees&quot;: attendees }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">functions = [{&quot;type&quot;: &quot;function&quot;, &quot;function&quot;: {&quot;type&quot;: &quot;object&quot;, &quot;name&quot;: &quot;schedule_meeting&quot;, &quot;description&quot;: &quot;Set a meeting at a specified date and time for designated attendees&quot;, &quot;parameters&quot;: {&quot;type&quot;: &quot;object&quot;, &quot;properties&quot;: {&quot;date&quot;: {&quot;type&quot;: &quot;string&quot;, &quot;format&quot;: &quot;date&quot;}, &quot;time&quot;: {&quot;type&quot;: &quot;string&quot;, &quot;format&quot;: &quot;time&quot;}, &quot;attendees&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}}}, &quot;required&quot;: [&quot;date&quot;, &quot;time&quot;, &quot;attendees&quot;]}}}]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">client = OpenAI(api_key=getenv(&quot;OPENAI_API_KEY&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">response = client.chat.completions.create(model=&quot;gpt-3.5-turbo-1106&quot;, messages=messages, tools=functions,)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.output_parsers.openai_tools import PydanticToolsParser</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tools = [convert_to_openai_tool(p) for p in pydantic_schemas]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model = model.bind_tools(tools=tools)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chain = prompt | model | PydanticToolsParser(tools=pydantic_schemas)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.chains.openai_tools import create_extraction_chain_pydantic</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chain = create_extraction_chain_pydantic(Person, model)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_core.prompts import FewShotChatMessagePromptTemplate, ChatPromptTemplate</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">few_shot_prompt = FewShotChatMessagePromptTemplate(example_prompt=example_prompt, examples=examples,)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.prompts.example_selector import LengthBasedExampleSelector</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">example_selector = LengthBasedExampleSelector(examples=examples, example_prompt=story_prompt, max_length=1000, get_text_length=num_tokens_from_string,)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dynamic_prompt = FewShotPromptTemplate(example_selector=example_selector, example_prompt=story_prompt, prefix=&#x27;Generate a story for {character}...&#x27;, suffix=&quot;Character: {character}\nStory:&quot;, input_variables=[&quot;character&quot;],)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_community.document_loaders import Docx2txtLoader</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_community.document_loaders import PyPDFLoader</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_community.document_loaders.csv_loader import CSVLoader</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">loader = PyPDFLoader(&quot;data/principles_of_marketing_book.pdf&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pages = loader.load_and_split()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.text_splitter import CharacterTextSplitter</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=200, chunk_overlap=0)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_text_splitters import RecursiveCharacterTextSplitter</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20, length_function=len)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docs = text_splitter.create_documents(texts, metadatas=[metadatas] * len(texts))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">splitted_docs = text_splitter.split_documents(docs)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_core.prompts.chat import ChatPromptTemplate</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">character_generation_prompt = ChatPromptTemplate.from_template(...)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from operator import itemgetter</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_core.runnables import RunnablePassthrough</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">master_chain = RunnablePassthrough() | {...}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_core.runnables import RunnableParallel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">character_script_generation_chain = ({...} | character_script_prompt | model | StrOutputParser())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_text_splitters import CharacterTextSplitter</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.chains.summarize import load_summarize_chain</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=1500, chunk_overlap=200)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docs = text_splitter.create_documents([all_character_script_text])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chain = load_summarize_chain(llm=model, chain_type=&quot;map_reduce&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">summary = chain.invoke(docs)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chain = load_summarize_chain(llm=model, chain_type=&#x27;refine&#x27;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-tags-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/lang-chain">LangChain</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/llm">LLM</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/prompt-engineering">Prompt Engineering</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/chat-models">Chat Models</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/output-parsers">Output Parsers</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/evaluation-metrics">Evaluation Metrics</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/function-calling">Function Calling</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/pydantic">Pydantic</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/query-planning">Query Planning</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/few-shot-learning">Few-Shot Learning</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/data-connection">Data Connection</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/text-splitters">Text Splitters</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/task-decomposition">Task Decomposition</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/document-loaders">Document Loaders</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/prompt-chaining">Prompt Chaining</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/sequential-chains">Sequential Chains</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/document-chains">Document Chains</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/summarization">Summarization</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/map-reduce">Map Reduce</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/refine-documents">Refine Documents</a></li></ul></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/AIEng/PromptEng/Standard Practices for Text Generation with ChatGPT_content"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">03. Standard Practices for Text Generation with ChatGPT</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/AIEng/PromptEng/Vector Databases with FAISS and Pinecone_content"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">05. Vector Databases with FAISS and Pinecone</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#titles" class="table-of-contents__link toc-highlight">titles</a></li><li><a href="#summary" class="table-of-contents__link toc-highlight">summary</a></li><li><a href="#code-snippets" class="table-of-contents__link toc-highlight">code snippets</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Tutorial</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://x.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/learn-with-ai/kb" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>