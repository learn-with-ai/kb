<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-AIEng/PromptEng/Autonomous Agents with Memory and Tools_content" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">06. Autonomous Agents with Memory and Tools | My Site</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://your-docusaurus-site.example.com/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://your-docusaurus-site.example.com/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://your-docusaurus-site.example.com/docs/AIEng/PromptEng/Autonomous Agents with Memory and Tools_content"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="06. Autonomous Agents with Memory and Tools | My Site"><meta data-rh="true" name="description" content="titles"><meta data-rh="true" property="og:description" content="titles"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://your-docusaurus-site.example.com/docs/AIEng/PromptEng/Autonomous Agents with Memory and Tools_content"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/docs/AIEng/PromptEng/Autonomous Agents with Memory and Tools_content" hreflang="en"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/docs/AIEng/PromptEng/Autonomous Agents with Memory and Tools_content" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="My Site RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="My Site Atom Feed"><link rel="stylesheet" href="/assets/css/styles.1724a0b2.css">
<script src="/assets/js/runtime~main.2d8c9eb9.js" defer="defer"></script>
<script src="/assets/js/main.ed51d313.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">My Site</b></a><a class="navbar__item navbar__link" href="/docs/SE/ModelDriven/Part1_">Tutorial</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/AIEng/AIDevops/Introduction_content">AI Engineering Docs</a><a class="navbar__item navbar__link" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/tags">Tags</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/AIEng/AIDevops/Introduction_content">AIDevops</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/AIEng/AIEngineering/Introduction to Building AI Applications with Foundation Models_content">AIEngineering</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/AIEng/LangChain/00Preface_content">LangChain</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/AIEng/PromptEng/The Five Principles of Prompting_content">PromptEng</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/PromptEng/The Five Principles of Prompting_content">01. The Five Principles of Prompting</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/PromptEng/Introduction to Large Language Models for Text Generation_content">02. Introduction to Large Language Models for Text Generation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/PromptEng/Standard Practices for Text Generation with ChatGPT_content">03. Standard Practices for Text Generation with ChatGPT</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/PromptEng/Advanced Techniques for Text Generation with LangChain_content">04. Advanced Techniques for Text Generation with LangChain</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/PromptEng/Vector Databases with FAISS and Pinecone_content">05. Vector Databases with FAISS and Pinecone</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/AIEng/PromptEng/Autonomous Agents with Memory and Tools_content">06. Autonomous Agents with Memory and Tools</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/PromptEng/Introduction to Diffusion Models for Image Generation_content">07. Introduction to Diffusion Models for Image Generation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/PromptEng/Standard Practices for Image Generation with Midjourney_content">08. Standard Practices for Image Generation with Midjourney</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/PromptEng/Advanced Techniques for Image Generation with Stable Diffusion_content">09. Advanced Techniques for Image Generation with Stable Diffusion</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AIEng/PromptEng/Building AI-Powered Applications_content">10. Building AI-Powered Applications</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/AIEng/ScalableAI/Introduction to Scalable AI Systems_content">ScalableAI</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">PromptEng</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">06. Autonomous Agents with Memory and Tools</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>06. Autonomous Agents with Memory and Tools</h1></header><h2 class="anchor anchorWithStickyNavbar_LWe7" id="titles">titles<a href="#titles" class="hash-link" aria-label="Direct link to titles" title="Direct link to titles">​</a></h2>
<p>Autonomous Agents with Memory and Tools Advanced Autonomous Agents with Memory and Tools Advanced Autonomous Agents with Memory and Tools Advanced Memory and Agent Frameworks in LangChain Token Counting and Chapter Summary on Autonomous Agents</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="summary">summary<a href="#summary" class="hash-link" aria-label="Direct link to summary" title="Direct link to summary">​</a></h2>
<ul>
<li>This chapter explores the significance of chain-of-thought reasoning in enhancing the problem-solving capabilities of large language models (LLMs) by breaking down complex problems into manageable components.</li>
<li>Chain-of-thought reasoning (CoT) is highlighted as a method to guide LLMs through logical steps to reach conclusions, especially useful for tasks requiring deep contextual understanding.</li>
<li>The chapter provides examples of ineffective and effective CoT, emphasizing the importance of step-by-step reasoning in prompts for generating relevant responses.</li>
<li>Autonomous agents are introduced as entities that perceive, act, and make decisions within an environment to achieve goals, with components like inputs, goal/reward functions, and available actions.</li>
<li>The ReAct framework is detailed as an advanced version of CoT, integrating reasoning with actions through tools, and includes a thought loop for problem-solving.</li>
<li>A practical implementation of ReAct in Python is discussed, focusing on extracting actions and inputs from LLM responses using regular expressions.</li>
<li>The chapter underscores the adaptability of LLMs through the integration of tools, expanding their action space beyond text generation to include API calls and database interactions.</li>
<li>Memory, agent planning/execution strategies, and retrieval methods are identified as key components enhancing LLM applications, particularly in chatbots.</li>
<li>The importance of crafting goal-driven directives and functional tools for LLMs is emphasized to guide their reasoning and expand their capabilities.</li>
<li>A diagram illustrating the ReAct framework&#x27;s comparative advantage over &#x27;Reason only&#x27; and &#x27;Act only&#x27; approaches is described, highlighting its integration of memory and tools for enhanced cognitive capabilities.</li>
<li>The chapter warns about the unpredictability of LLM responses and suggests handling regex parsing errors by using an LLM to fix previous responses or making new requests.</li>
<li>A step-by-step guide is provided for initializing a ChatOpenAI instance, defining available tools, and setting a base prompt template for ReAct implementation.</li>
<li>The process of generating model output, extracting actions and inputs, and calling relevant functions is detailed, emphasizing the importance of structured outputs.</li>
<li>The chapter introduces the concept of using tools to extend LLM capabilities, detailing three approaches: creating custom tools, using preexisting tools, and leveraging AgentToolkits.</li>
<li>A practical example demonstrates creating a custom tool in LangChain to count characters in a string, showcasing the integration of tools with LLMs.</li>
<li>The use of AgentExecutor for detailed logging and the importance of expressive names for Python functions and tool descriptions are highlighted.</li>
<li>OpenAI Functions are presented as an alternative to the ReAct pattern, with a focus on their ease of implementation and suitability for tasks requiring single tool execution.</li>
<li>A comparison between OpenAI Functions and ReAct is provided, outlining their unique capabilities and ideal use cases.</li>
<li>The chapter concludes with recommendations for monitoring tool usage and dividing tasks appropriately to enhance LLM agent performance.</li>
<li>An image description illustrates the function calling flow using OpenAI functions, emphasizing the practical application of autonomous agents in gathering information dynamically.</li>
<li>The chapter provides a feature comparison between OpenAI functions and ReAct, highlighting their strengths and trade-offs for different AI frameworks.</li>
<li>Agent toolkits in LangChain are introduced as a way to quickly automate tasks by bundling multiple tools together, with examples including CSV Agent and SQLDatabase Agent.</li>
<li>A practical guide is given for creating a CSV Agent to interact with .csv files, demonstrating how to quantify data, identify column names, and create correlation matrices.</li>
<li>The SQLDatabase agent is showcased for interacting with SQL databases, including adding new users and querying the database, emphasizing the importance of understanding database schemas.</li>
<li>Customizing standard agents in LangChain is discussed, with key function arguments like prefix, suffix, max_iterations, and max_execution_time highlighted for limiting API and compute costs.</li>
<li>The chapter explains how to create custom agents using LCEL (LangChain Expression Language), including setting up prompts, binding tools to LLMs, and setting up agent chains.</li>
<li>Memory in LangChain is explored, distinguishing between long-term memory (LTM) and short-term memory (STM) and their applications in enhancing LLM interactions.</li>
<li>Practical applications of memory in QA conversation agents are illustrated, showing how STM allows for seamless continuation of conversations and anticipation of follow-up questions.</li>
<li>The ConversationBufferMemory in LangChain is detailed as a popular memory type that stores multiple chat messages without restriction on history size, with examples of integration into chains.</li>
<li>The chapter concludes with instructions on adding memory to an agent by incorporating a MessagesPlaceholder into the ChatPromptTemplate and memory into the AgentExecutor, enabling the use of previous messages to answer new queries.</li>
<li>The chapter explores advanced memory management techniques in LangChain, including ConversationBufferWindowMemory, ConversationSummaryMemory, ConversationSummaryBufferMemory, and ConversationTokenBufferMemory, each suited for different scenarios based on conversation length and token limits.</li>
<li>It highlights the importance of choosing the right memory type for specific needs, such as maintaining recent interactions or summarizing extended conversations to save token space.</li>
<li>The chapter introduces advanced agent frameworks like Plan-and-Execute Agents (including BabyAGI and AutoGPT) and the Tree of Thoughts (ToT) framework, which enhances problem-solving by allowing exploration of multiple reasoning paths.</li>
<li>A detailed example of BabyAGI&#x27;s agent architecture is provided, showcasing how it integrates OpenAI LLMs with vector databases for adaptive task management.</li>
<li>The Tree of Thoughts framework is presented as a paradigm shift in AI problem-solving, enabling models to explore various reasoning trajectories and significantly improving success rates in complex tasks.</li>
<li>LangChain&#x27;s callbacks are introduced as a powerful tool for monitoring and debugging applications, with examples of global and request-specific callbacks and their appropriate use cases.</li>
<li>The chapter concludes with practical advice on using verbose arguments for debugging and the strategic application of constructor and request callbacks in large projects.</li>
<li>The chapter concludes with a focus on token counting in LangChain, demonstrating how to measure token usage during interactions with generative AI models using the <code>get_openai_callback</code> context manager.</li>
<li>It explains the importance of monitoring token usage for budgeting and optimizing prompts, with examples showing how to count tokens for single and multiple requests, including concurrent executions.</li>
<li>The <code>get_openai_callback</code> context manager provides detailed metrics such as successful requests, total cost, total tokens, prompt tokens, and completion tokens, offering insights into API usage and response verbosity.</li>
<li>A summary of the chapter revisits the key concepts covered, including chain-of-thought reasoning, agent-based architecture in generative AI, memory integration, and advanced agent frameworks like ReAct and OpenAI function calling.</li>
<li>The chapter sets the stage for the next topic, which will explore image generation using generative AI, promising to cover the history, strengths, and weaknesses of various models and vendors.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="code-snippets">code snippets<a href="#code-snippets" class="hash-link" aria-label="Direct link to code snippets" title="Direct link to code snippets">​</a></h2>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import re</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Sample text:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">text = &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Action: search_on_google</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Action_Input: Tom Hanks&#x27;s current wife</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">action: search_on_wikipedia</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">action_input: How old is Rita Wilson in 2023</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">action : search_on_google</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">action input: some other query</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Compile regex patterns:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">action_pattern = re.compile(r&quot;(?i)action\s*:\s*([^\n]+)&quot;, re.MULTILINE)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">action_input_pattern = re.compile(r&quot;(?i)action\s*_*input\s*:\s*([^\n]+)&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">re.MULTILINE)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Find all occurrences of action and action_input:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">actions = action_pattern.findall(text)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">action_inputs = action_input_pattern.findall(text)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def extract_last_action_and_input(text):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Compile regex patterns</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    action_pattern = re.compile(r&quot;(?i)action\s*:\s*([^\n]+)&quot;, re.MULTILINE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    action_input_pattern = re.compile(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        r&quot;(?i)action\s*_*input\s*:\s*([^\n]+)&quot;, re.MULTILINE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Find all occurrences of action and action_input</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    actions = action_pattern.findall(text)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    action_inputs = action_input_pattern.findall(text)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Extract the last occurrence of action and action_input</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    last_action = actions[-1] if actions else None</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    last_action_input = action_inputs[-1] if action_inputs else None</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return {&quot;action&quot;: last_action, &quot;action_input&quot;: last_action_input}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def extract_final_answer(text):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    final_answer_pattern = re.compile(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        r&quot;(?i)I&#x27;ve found the answer:\s*([^\n]+)&quot;, re.MULTILINE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    final_answers = final_answer_pattern.findall(text)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_openai.chat_models import ChatOpenAI</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.prompts.chat import SystemMessagePromptTemplate</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chat = ChatOpenAI(model_kwargs={&quot;stop&quot;: [&quot;tool_result:&quot;],})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def count_characters_in_string(string):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return len(string)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tools = [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Tool.from_function(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        func=count_characters_in_string,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        name=&quot;Count Characters in a text string&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        description=&quot;Count the number of characters in a text string&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.agents import AgentExecutor, create_react_agent</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain import hub</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_openai import ChatOpenAI</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.tools import Tool</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model = ChatOpenAI()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">prompt = hub.pull(&quot;hwchase17/react&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">agent = create_react_agent(model, tools, prompt)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.chains import LLMMathChain</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain import hub</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.agents import create_openai_functions_agent, Tool, AgentExecutor</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_openai.chat_models import ChatOpenAI</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model = ChatOpenAI(temperature=0)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">llm_math_chain = LLMMathChain.from_llm(llm=model, verbose=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">prompt = hub.pull(&quot;hwchase17/openai-functions-agent&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def google_search(query: str) -&gt; str:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return &quot;James Phoenix is 31 years old.&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tools = [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Tool(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        func=llm_math_chain.run,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        name=&quot;Calculator&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        description=&quot;useful for when you need to answer questions about math&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Tool(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        func=google_search,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        name=&quot;google_search&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        description=&quot;useful for when you need to find out about someones age&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.agents.agent_types import AgentType</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_experimental.agents.agent_toolkits import create_csv_agent</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_openai.chat_models import ChatOpenAI</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">agent = create_csv_agent(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ChatOpenAI(temperature=0),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;data/heart_disease_uci.csv&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    verbose=True,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.agents import create_sql_agent</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_community.agent_toolkits import SQLDatabaseToolkit</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.sql_database import SQLDatabase</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.agents.agent_types import AgentType</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_openai.chat_models import ChatOpenAI</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">db = SQLDatabase.from_uri(&quot;sqlite:///./data/demo.db&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">toolkit = SQLDatabaseToolkit(db=db, llm=ChatOpenAI(temperature=0))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">agent_executor = create_sql_agent(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    llm=ChatOpenAI(temperature=0),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    toolkit=toolkit,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    verbose=True,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    agent_type=AgentType.OPENAI_FUNCTIONS,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_openai import ChatOpenAI</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_core.tools import tool</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">llm = ChatOpenAI(temperature=0)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@tool</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def get_word_length(word: str) -&gt; int:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;&quot;&quot;Returns the length of a word.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return len(word)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tools = [get_word_length]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.memory import ConversationBufferMemory</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">memory = ConversationBufferMemory()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">memory.save_context({&quot;input&quot;: &quot;hi&quot;}, {&quot;output&quot;: &quot;whats up&quot;})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">memory.load_memory_variables({})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.memory import ConversationBufferMemory</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_openai.chat_models import ChatOpenAI</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_core.output_parsers import StrOutputParser</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_core.runnables import RunnableLambda</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from operator import itemgetter</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">memory = ConversationBufferMemory(return_messages=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model = ChatOpenAI(temperature=0)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">prompt = ChatPromptTemplate.from_messages(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        (&quot;system&quot;, &quot;Act as a chatbot that helps users with their queries.&quot;),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        MessagesPlaceholder(variable_name=&quot;history&quot;),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        (&quot;human&quot;, &quot;{input}&quot;),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chain = (</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;input&quot;: lambda x: x[&quot;input&quot;],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;history&quot;: RunnableLambda(memory.load_memory_variables) | itemgetter(&quot;history&quot;),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    | prompt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    | model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    | StrOutputParser()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.memory import ConversationBufferWindowMemory</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">memory = ConversationBufferWindowMemory(k=1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">memory.save_context({&quot;input&quot;: &quot;hi&quot;}, {&quot;output&quot;: &quot;whats up&quot;})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">memory.save_context({&quot;input&quot;: &quot;not much you&quot;}, {&quot;output&quot;: &quot;not much&quot;})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">memory.load_memory_variables({})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.memory import ConversationSummaryMemory, ChatMessageHistory</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_openai import OpenAI</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">memory = ConversationSummaryMemory(llm=OpenAI(temperature=0))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">memory.save_context({&quot;input&quot;: &quot;hi&quot;}, {&quot;output&quot;: &quot;whats up&quot;})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">memory.load_memory_variables({})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.memory import ConversationSummaryBufferMemory</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_openai.chat_models import ChatOpenAI</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">memory = ConversationSummaryBufferMemory(llm=ChatOpenAI(), max_token_limit=40)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">memory.save_context({&quot;input&quot;: &quot;hi&quot;}, {&quot;output&quot;: &quot;whats up&quot;})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">memory.load_memory_variables({})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.memory import ConversationTokenBufferMemory</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_openai.chat_models import ChatOpenAI</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">memory = ConversationTokenBufferMemory(llm=ChatOpenAI(), max_token_limit=50)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">memory.save_context({&quot;input&quot;: &quot;hi&quot;}, {&quot;output&quot;: &quot;whats up&quot;})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">memory.load_memory_variables({})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.callbacks import StdOutCallbackHandler</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.chains import LLMChain</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_openai import OpenAI</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_core.prompts import PromptTemplate</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">handler = StdOutCallbackHandler()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">llm = OpenAI()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">prompt = PromptTemplate.from_template(&quot;What is 1 + {number} = &quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chain = LLMChain(llm=llm, prompt=prompt)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chain.invoke({&quot;number&quot;: 2}, {&quot;callbacks&quot;: [handler]})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import asyncio</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain.callbacks import get_openai_callback</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_core.messages import SystemMessage</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_openai.chat_models import ChatOpenAI</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model = ChatOpenAI()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">with get_openai_callback() as cb:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model.invoke([SystemMessage(content=&quot;My name is James&quot;)])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">total_tokens = cb.total_tokens</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(total_tokens)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 25</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">with get_openai_callback() as cb:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model.invoke([SystemMessage(content=&quot;My name is James&quot;)])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model.invoke([SystemMessage(content=&quot;My name is James&quot;)])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">assert cb.total_tokens &gt; 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(cb.total_tokens)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 50</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Async callbacks:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">with get_openai_callback() as cb:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    await asyncio.gather(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        model.agenerate(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                [SystemMessage(content=&quot;Is the meaning of life 42?&quot;)],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                [SystemMessage(content=&quot;Is the meaning of life 42?&quot;)],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            ],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(cb.__dict__)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># {&#x27;successful_requests&#x27;: 2, &#x27;total_cost&#x27;: 0.000455,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># &#x27;total_tokens&#x27;: 235, &#x27;prompt_tokens&#x27;: 30,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># &#x27;completion_tokens&#x27;: 205}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-tags-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/chain-of-thought-reasoning">Chain-of-Thought reasoning</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/autonomous-agents">Autonomous Agents</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/re-act-framework">ReAct framework</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/ll-ms">LLMs</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/prompt-engineering">Prompt Engineering</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/re-act-implementation">ReAct implementation</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/lang-chain-agents">LangChain agents</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/open-ai-functions">OpenAI Functions</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/tool-creation">Tool creation</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/agent-comparison">Agent comparison</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/agent-toolkits">Agent Toolkits</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/memory-in-lang-chain">Memory in LangChain</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/custom-agents">Custom Agents</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/sql-database-agent">SQLDatabase Agent</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/conversation-buffer-memory">ConversationBufferMemory</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/memory-types">Memory Types</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/agent-frameworks">Agent Frameworks</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/lang-chain">LangChain</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/tree-of-thoughts">Tree of Thoughts</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/token-counting">Token Counting</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/open-ai">OpenAI</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/chain-of-thought-reasoning">Chain-of-Thought Reasoning</a></li></ul></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/AIEng/PromptEng/Vector Databases with FAISS and Pinecone_content"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">05. Vector Databases with FAISS and Pinecone</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/AIEng/PromptEng/Introduction to Diffusion Models for Image Generation_content"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">07. Introduction to Diffusion Models for Image Generation</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#titles" class="table-of-contents__link toc-highlight">titles</a></li><li><a href="#summary" class="table-of-contents__link toc-highlight">summary</a></li><li><a href="#code-snippets" class="table-of-contents__link toc-highlight">code snippets</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Tutorial</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://x.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/learn-with-ai/kb" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>