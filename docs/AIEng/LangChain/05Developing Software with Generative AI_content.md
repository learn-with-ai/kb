---
sidebar_position: 1
tags: ["Generative AI", "LLMs", "Software Development", "LangChain", "Code Generation"]
title: "05Developing Software with Generative AI"
---

## summary

- The chapter explores the integration of generative AI, particularly LLMs, into software development, highlighting its significant impact on the field as reported by consultancies like KPMG and McKinsey.
- It discusses the automation of software development tasks through LLMs, including coding, code summarization, bug fixing, and test generation, emphasizing the balance between automation and human oversight.
- The chapter introduces various AI models like OpenAI’s Codex, GitHub’s Copilot, and DeepMind’s AlphaCode, showcasing their capabilities in code generation and the potential to revolutionize software engineering.
- Performance benchmarks like the HumanEval dataset are discussed to evaluate LLMs' coding abilities, with insights into how high-quality data can enhance model performance beyond mere size scaling.
- The Reflexion framework is highlighted as a novel approach to improve LLMs' coding task performance through trial-and-error-based learning and verbal reinforcement.
- Practical implementation includes an automated software developer project available on GitHub, demonstrating LangChain's flexibility in integrating various code generation models.
- The chapter concludes with a demonstration of code generation using models like Vertex AI’s PaLM and StarCoder, illustrating LangChain's diverse integrations and the practical application of these technologies in solving common programming challenges like FizzBuzz.
- Important images include a comparison of open-source models on the HumanEval coding task benchmark and a screenshot of the StarCoder Models Playground, providing visual insights into model performance and practical exploration tools.
- The chapter delves into automating software development using generative AI, showcasing various models like StarCoder, StarChat, and Llama 2 for code generation tasks.
- It highlights the challenges and limitations of using LLMs for code generation, including issues with code correctness, readability, and the need for human oversight.
- Practical examples demonstrate generating code snippets for tasks like creating a customer data model and calculating prime numbers, emphasizing the iterative process of refining AI-generated code.
- The chapter introduces LangChain integrations for code execution, such as LLMMathChain and BashChain, and explores the potential of feedback loops in improving AI-generated code.
- Advanced frameworks like MetaGPT and llm-strategy are discussed for their innovative approaches to human-LLM collaboration in software development.
- Important images include a screenshot of StarChat implementing a function for calculating prime numbers and a depiction of the collaborative process between humans and AI in code refinement.
- The chapter explores the automation of software development using generative AI, focusing on the integration of LLMs to assist in coding tasks, debugging, and iterative code refinement.
- It highlights the importance of feedback loops in improving AI-generated code, where the LLM assesses its output, debugs issues, and refines the code based on execution results.
- Various tools and frameworks like LangChain's PlanAndExecute chain, ZeroShotAgent, and BabyAGI are discussed for implementing feedback loops in code generation.
- The chapter emphasizes the security risks associated with executing LLM-generated code and suggests sandboxing tools like RestrictedPython and pychroot for safe execution.
- Practical examples include generating a basic Tetris game in Python, showcasing the potential and limitations of current LLM capabilities in software development.
- The discussion extends to the future of human-LLM collaboration in software development, advocating for human oversight in high-level design and rigorous review to ensure code quality.
- Important images include a flowchart illustrating the Code-It control flow for generative AI in software development and a screenshot of a Python game window generated by an LLM.
- The chapter concludes with a summary of LLMs' role in software development, the necessity of human-AI collaboration, and a teaser for the next chapter on LLMs for data science.

## code snippets
```
def fizzBuzz(n):
    answer = []
    for i in range(1, n + 1):
        if i % 3 == 0 and i % 5 == 0:
            answer.append("FizzBuzz")
        elif i % 3 == 0:
            answer.append("Fizz")
        elif i % 5 == 0:
            answer.append("Buzz")
        else:
            answer.append(str(i))
    return answer
@dataclass(frozen=True)
class Customer:
    cust_id : str = field()
    firstname : str = ""
    lastname : str = ""
    def __post_init__(self):
        self._validate_cust_id()
        self.__set_fullname__()
def calculate_primes(n):
    lst = set()
    for i in range(2, n + 1):
        if i not in lst:
            lst.add(i)
        if len(lst) > 2:
            break
    else:
        return sorted(list(lst))
    return [i for i in lst if sum(lst[-3:]) == (p := 2) ** 2]
from langchain import hub
from langchain.agents import create_react_agent, AgentExecutor
from langchain.agents import Tool
from langchain_experimental.utilities import PythonREPL
from langchain_openai import OpenAI
llm = OpenAI()
python_repl = PythonREPL()
repl_tool = Tool(
    name="python_repl",
    description="A Python shell. Use this to execute python commands. Input should be a valid python command.",
    func=python_repl.run,
)
from langchain_experimental.autonomous_agents.hugginggpt.task_planner import load_chat_planner
from langchain_experimental.plan_and_execute import PlanAndExecute, load_agent_executor
from langchain_openai import OpenAI
llm = OpenAI()
planner = load_chat_planner(llm)
executor = load_agent_executor(
    llm,
    tools=tools,
    verbose=True,
)
agent_executor = PlanAndExecute(
    planner=planner,
    executor=executor,
    verbose=True,
    handle_parsing_errors="Check your output and make sure it conforms!",
    return_intermediate_steps=True
)
agent_executor.invoke({"input": "Write a tetris game in python!"})
import pygame
import sys
pygame.init()
window_width = 800
window_height = 600
window = pygame.display.set_mode((window_width, window_height))
pygame.display.set_caption('My Game')
background_color = (255, 255, 255)
while True:
    for event in pygame.event.get():
        if event.type == pygame.QUIT:
            pygame.quit()
            sys.exit()
    window.fill(background_color)
    pygame.display.update()
from langchain_core.tools import Tool
from .python_developer import PythonDeveloper, PythonExecutorInput
software_dev = PythonDeveloper(llm_chain=software_llm)
code_tool = Tool.from_function(
    func=software_dev.run,
    name="PythonREPL",
    description=(
        "You are a software engineer who writes Python code given a function description."
    ),
    args_schema=PythonExecutorInput
)
```
