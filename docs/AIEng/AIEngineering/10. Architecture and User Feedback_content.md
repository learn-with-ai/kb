---
sidebar_position: 1
tags: ["Foundation Models", "Retrieval-Augmented Generation (RAG)", "Guardrails", "Model Routing", "Intent Classifiers", "Routing", "Model Gateway", "Caching", "Semantic Similarity", "Agent Patterns", "Observability", "Monitoring", "Metrics", "Logs", "AI Pipeline Orchestration", "User Feedback", "Explicit Feedback", "Implicit Feedback", "Natural Language Processing", "Reinforcement Learning", "User Feedback Systems", "AI Model Training", "Feedback Collection Design", "Bias in Feedback", "Degenerate Feedback Loops", "AI Engineering", "Data Flywheel", "Product Experience", "System Problems"]
title: "10. Architecture and User Feedback"
---

## summary

- The chapter discusses integrating various AI engineering techniques to build successful products, emphasizing the importance of user feedback for model improvement.
- It presents a gradual approach to architecture design, starting simple and adding components like context enhancement, guardrails, and model routing to address challenges.
- User feedback is highlighted as crucial for AI applications, especially those with conversational interfaces, for both product development and model improvement.
- The simplest architecture involves sending a query to a model and returning the response, with options to enhance this with external data, tools, and security measures.
- Context construction is likened to feature engineering for foundation models, vital for output quality, with differences in support across model API providers.
- Guardrails are introduced to mitigate risks, categorized into input and output guardrails, with strategies for handling sensitive data and model failures.
- Model routing and gateways are discussed as solutions for managing complexity and costs when serving multiple models, using intent classifiers for efficient query handling.
- Practical steps include enhancing context, implementing guardrails, and adding model routers, with considerations for latency, cost, and user experience.
- Real-world applications include customer support chatbots, technical troubleshooting, and billing inquiries, showcasing the versatility of AI architectures.
- The chapter concludes with the importance of monitoring, observability, and orchestration in maintaining application quality and performance.
- Important images include diagrams illustrating simple AI application architecture, context construction, and the addition of guardrails and model routing.
- Routing in AI applications helps determine the optimal solution for each query, occurring both before and after retrieval.
- A model gateway serves as a unified and secure interface to different models, simplifying maintenance and updates.
- The chapter discusses the importance of model gateways in providing access control, cost management, and implementing fallback policies.
- Caching techniques, including exact and semantic caching, are explored to reduce latency and manage costs in AI applications.
- Exact caching uses cached items only when identical queries are made, while semantic caching leverages semantically similar queries.
- Semantic caching relies on high-quality embeddings and vector search, posing challenges in reliability and performance.
- Agent patterns introduce complexity into application flows, enabling loops, parallel execution, and conditional branching.
- Write actions, though risky, can significantly enhance a system's capabilities by allowing direct changes to the environment.
- The architecture's complexity increases with added functionalities, introducing more failure modes and debugging challenges.
- Images in the chapter illustrate AI system architectures, including context construction, input guardrails, and model gateways, highlighting modular integration and flexibility.
- Practical implementation opportunities include setting up model gateways, implementing caching strategies, and incorporating agent patterns for complex applications.
- Observability is crucial in the design of complex products, with established best practices and solutions available to avoid reinventing the wheel.
- Monitoring aims to mitigate risks like application failures and security attacks, and to discover opportunities for improvement and cost savings.
- Key metrics for observability include MTTD, MTTR, and CFR, which help evaluate and improve system performance.
- Monitoring and observability differ in that observability assumes the system's internal states can be inferred from external outputs, facilitating easier debugging.
- Metrics should be designed around potential failure modes, such as detecting hallucinations in AI outputs or tracking API costs.
- For open-ended AI generations, monitoring should include factual consistency, creativity, and safety-related metrics.
- User feedback and conversational signals provide valuable insights into model quality and user experience.
- Each component in an application pipeline has specific metrics, such as retrieval quality in RAG applications or query times in vector databases.
- Latency and cost metrics are essential for understanding user experience and ensuring efficient resource use.
- Logs and traces are vital for debugging, with logs providing a record of events and traces linking related events to form a complete timeline.
- Drift detection is important for identifying changes in system prompts, user behavior, or underlying models that could affect performance.
- AI Pipeline Orchestration involves defining components and chaining them to create an end-to-end pipeline, with tools like LangChain and LlamaIndex facilitating this process.
- User feedback is a competitive advantage in AI applications, informing performance evaluation and development.
- The chapter includes detailed descriptions of architectural diagrams and interfaces, highlighting the importance of design in system performance and user interaction.
- User feedback is invaluable for personalizing AI models and training future iterations, leveraging proprietary data for competitive advantage.
- Respecting user privacy and transparency about data usage is crucial when leveraging user feedback.
- Feedback can be explicit (direct responses) or implicit (inferred from user actions), with explicit feedback being more standardized and implicit feedback being application-dependent.
- Conversational interfaces facilitate natural feedback, allowing users to correct or encourage AI behaviors as they would in daily dialogues.
- Feedback from conversations can be used for evaluation, development, and personalization of AI applications.
- Natural language feedback, including early termination and error correction, provides insights into user satisfaction and model performance.
- User edits to model outputs serve as strong signals for model improvement and preference data for alignment.
- Complaints and sentiment analysis offer additional layers of feedback, highlighting areas for improvement in AI responses.
- Regeneration and conversation organization actions provide implicit feedback on user satisfaction and preferences.
- Feedback design should be nonintrusive, allowing users to report errors and preferences throughout their journey with the application.
- Initial calibration feedback can help tailor the application to new users, though it should be optional to reduce friction.
- Human-AI collaboration features, like inpainting in image generation, enhance user experience and provide high-quality feedback.
- Comparative feedback mechanisms, such as side-by-side response evaluation, can guide model improvement but may introduce noise.
- The chapter emphasizes the importance of understanding and leveraging both explicit and implicit feedback for continuous AI model improvement.
- Important images include examples of conversational feedback, inpainting functionality, and comparative feedback interfaces.
- Google Photos and other applications ask for user feedback when unsure, highlighting the importance of feedback in improving AI applications.
- Apple’s human interface guideline advises against asking for both positive and negative feedback to avoid giving users the impression that good results are exceptions.
- Positive feedback is valuable for identifying high-impact features, but its collection must be managed to avoid interface clutter or user annoyance.
- Feedback should integrate seamlessly into the user’s workflow, as exemplified by Midjourney’s implicit feedback collection through user choices.
- GitHub Copilot demonstrates effective feedback collection by allowing users to accept or ignore suggestions easily, contrasting with standalone AI applications like ChatGPT.
- Feedback collection must consider user privacy and consent, especially when context is needed for deeper analysis.
- Explaining how feedback is used can motivate users to provide more and better feedback, emphasizing transparency and privacy assurances.
- Avoid designs that confuse users or ask for impossible comparisons, as seen in a ChatGPT example asking users to choose between statistical answers.
- Feedback visibility affects user behavior and experience, with private feedback often yielding more candid responses.
- User feedback is subject to various biases, including leniency bias, randomness, position bias, and preference bias, which must be understood and mitigated.
- Degenerate feedback loops can amplify initial biases, affecting product focus and user base, as illustrated by video recommendation systems.
- Acting on user feedback without understanding its limitations can perpetuate biases and harm the product, highlighting the need for careful feedback incorporation.
- The chapter provides a framework for building AI applications, emphasizing modularity, observability, and the importance of user feedback in continuous improvement.
- Observability and monitoring are crucial for detecting new failure modes introduced by foundation models in AI applications.
- User feedback design is increasingly recognized as an engineering responsibility, essential for the data flywheel in AI model improvement.
- AI engineering is increasingly focusing on product development, emphasizing the importance of the data flywheel and product experience as competitive advantages.
- Many challenges in AI are systemic, requiring a holistic approach to solve, where understanding the entire system is crucial for addressing real problems and ensuring safety.
- An incident involving Samsung highlights the risks of proprietary information leakage when using AI models like ChatGPT.
- User feedback mechanisms are discussed, including the challenges of collecting feedback from open source applications compared to commercial ones.
- The potential of using AI to analyze feedback about AI applications is explored, suggesting a recursive improvement loop.
- A personal anecdote about text-to-speech technology illustrates the desire for more granular control over AI outputs, such as editing specific mistakes without regenerating entire audio.
- The debate on showing full responses to users for feedback purposes is presented, highlighting differing opinions on its effectiveness.
- References to political incidents involving social media misuse underscore the importance of secure and responsible AI use.
- The chapter mentions the significant market capitalization of observability companies, indicating the growing importance of monitoring in AI systems.
- A reference to the author's previous work on monitoring in machine learning systems provides additional resources for readers interested in the topic.
- The tendency of orchestrator tools to evolve into end-to-end platforms is noted, reflecting the industry's move towards comprehensive solutions.
- Important images or descriptions mentioned in the book are not explicitly referenced in the provided text.

## code snippets
```
No direct code references found in the chapter.
import google.generativeai as genai
import openai
def openai_model(input_data, model_name, max_tokens):
def gemini_model(input_data, model_name, max_tokens):
@app.route('/model', methods=['POST'])
def model_gateway():
```
