---
sidebar_position: 1
tags: ["Prompt Engineering", "In-context Learning", "System Prompt", "User Prompt", "Context Length", "AI Models", "Chain-of-Thought (CoT)", "Self-critique", "Context Construction", "Promptbreeder", "Guidance", "Outlines", "Instructor", "LangChain", "AI Security", "Automated Attacks", "Indirect Prompt Injection", "Training Data Extraction", "LLMs", "Instruction Hierarchy", "Safety Finetuning", "Prompt-level Defense"]
title: "05. Prompt Engineering"
---

## summary

- Prompt engineering is the process of crafting instructions to guide AI models to generate desired outcomes without altering the model's weights, making it a resource-efficient adaptation technique.
- Effective communication with AI models through prompts is likened to human communication, where clarity and effectiveness are key.
- The chapter emphasizes the importance of systematic experimentation in prompt engineering, similar to rigorous ML experiments.
- A research manager at OpenAI highlights prompt engineering as a valuable skill but notes its insufficiency alone for production-ready AI applications, which also require statistics, engineering, and classic ML knowledge.
- Prompts can consist of task descriptions, examples, and the concrete task, with their effectiveness depending on the model's instruction-following capability.
- The concept of in-context learning is introduced, allowing models to learn from examples within the prompt without weight updates, enabling continual learning.
- System and user prompts are differentiated, with system prompts acting as task descriptions and user prompts as the tasks themselves, offering flexibility in structuring prompts for optimal performance.
- Context length and its rapid expansion are discussed, highlighting its importance in fitting more information into prompts and the varying effectiveness of prompt parts based on their position.
- Best practices for prompt engineering are distilled from tutorials by leading model providers, focusing on techniques that remain relevant across models.
- The chapter includes practical insights into evaluating model robustness and the impact of prompt structure on performance.
- Images in the chapter illustrate concepts like NER tasks, the progression of context length over time, and the effect of information position in prompts on model performance.
- Prompt engineering involves crafting clear and explicit instructions to guide AI models in generating desired outputs.
- Each AI model may respond differently to specific prompt tricks, necessitating model-specific prompt engineering guides.
- Clear instructions can mitigate undesirable behaviors, such as fractional scores, by specifying exact requirements like integer-only outputs.
- Adopting a persona can help the model generate responses from a specific perspective, enhancing relevance and appropriateness.
- Providing examples reduces ambiguity and guides the model towards the desired response format and content.
- Specifying the output format, such as JSON, ensures compatibility with downstream applications and reduces unnecessary verbosity.
- Sufficient context improves model performance and reduces hallucinations by grounding responses in provided information.
- Restricting a model's knowledge to only its context is crucial for role-playing and simulations, though challenging to enforce reliably.
- Breaking complex tasks into simpler subtasks enhances performance, allows for parallelization, and simplifies debugging.
- Chain-of-Thought (CoT) prompting encourages models to 'think' step by step, improving problem-solving accuracy and reducing hallucinations.
- Self-critique prompts models to evaluate their own outputs, fostering more accurate and thoughtful responses.
- Iterative prompt refinement, based on model responses and experimentation, is key to effective prompt engineering.
- Automated prompt engineering tools, like OpenPrompt and DSPy, can optimize prompts based on specified metrics and data.
- AI models themselves can generate, critique, and improve prompts, offering a recursive approach to prompt optimization.
- The chapter includes practical examples and tables illustrating prompt variations and their impacts on model responses.
- Interesting insights include the effectiveness of CoT prompting across different model sizes and tasks, as shown in referenced studies.
- Practical steps involve experimenting with prompt variations, versioning prompts, and systematically evaluating their performance.
- Real-world applications range from customer support chatbots to educational tools, highlighting the versatility of prompt engineering.
- Key takeaways include the importance of clarity, context, and iterative refinement in crafting effective prompts for AI models.
- Important images and descriptions in the book illustrate the impact of persona adoption and CoT prompting on model responses.
- Promptbreeder is introduced as a method to iteratively improve prompts by generating and selecting mutations guided by mutator prompts, enhancing AI model performance.
- Tools like Guidance, Outlines, and Instructor assist in guiding models towards structured outputs and perturbing prompts for optimization.
- The importance of understanding the underlying mechanisms of prompt engineering tools is emphasized to avoid unnecessary costs and inefficiencies.
- Figure 5-8 illustrates the Promptbreeder process, showing how initial prompts are mutated and selected for further refinement.
- The chapter discusses the separation of prompts from code for reusability, testing, readability, and collaboration, suggesting the use of a prompts.py file for organization.
- Versioning prompts and organizing them with metadata in a prompt catalog is recommended for managing multiple applications and facilitating search and collaboration.
- Defensive prompt engineering is highlighted to protect against prompt extraction, jailbreaking, and information extraction, outlining the risks associated with each.
- The concept of reverse prompt engineering is discussed, where attackers deduce system prompts to replicate or manipulate applications, emphasizing the need for prompt security.
- Jailbreaking and prompt injection attacks are explained, detailing how models can be manipulated to perform undesirable actions, with examples of common attack techniques.
- The chapter concludes with a discussion on the evolving nature of AI safety, comparing it to cybersecurity's cat-and-mouse game between developers and attackers.
- Images in the chapter include descriptions of AI-generated applications for grading essays and diagrams illustrating prompt engineering processes, providing visual context for the concepts discussed.
- The chapter discusses various techniques and vulnerabilities in prompt engineering, including automated attacks and indirect prompt injections.
- Automated attacks can be executed by algorithms that substitute parts of a prompt to find variations that bypass AI safety measures.
- Indirect prompt injection involves placing malicious instructions in tools integrated with the model, rather than directly in the prompt.
- Passive phishing and active injection are two approaches to indirect prompt injection, leveraging public spaces or direct communication to deliver malicious payloads.
- Training data extraction is a risk where models can divulge sensitive or copyrighted information from their training data through specific prompts.
- Factual probing techniques can be used to extract relational knowledge or sensitive information from models, highlighting privacy and copyright concerns.
- Defenses against prompt attacks include understanding system vulnerabilities, employing security benchmarks, and implementing model, prompt, and system-level defenses.
- Metrics like violation rate and false refusal rate are crucial for evaluating a system's robustness against prompt attacks without compromising usability.
- The chapter emphasizes the importance of not training models on copyrighted materials to avoid legal risks associated with copyright regurgitation.
- Image descriptions in the chapter illustrate methods for crafting targeted queries in AI systems and the process of generating images based on original samples, showcasing applications of prompt engineering.
- Practical steps include employing security red teams to devise new attacks and defenses, and using tools like Azure/PyRIT for automated security probing.
- OpenAI introduces an instruction hierarchy with four levels of priority to manage conflicting instructions and neutralize indirect prompt injection attacks.
- Finetuning models for safety involves recognizing malicious prompts and generating safe responses for borderline requests to balance safety with helpfulness.
- Prompt-level defense strategies include being explicit about restrictions, duplicating system prompts to remind the model of its task, and inspecting default prompt templates for safety instructions.
- System-level defense practices include isolating execution environments, requiring human approvals for impactful commands, and defining out-of-scope topics to prevent inappropriate responses.
- Advanced algorithms analyze entire conversations to block inappropriate requests or direct them to human operators, using anomaly detection to identify unusual prompts.
- Guardrails are essential for both inputs and outputs to detect and block harmful content, with usage patterns helping to identify bad actors.
- Prompt engineering is crucial for effective human-AI communication, requiring clear instructions, examples, and consideration of model quirks and biases.
- Security risks in AI adoption remain a significant challenge, with prompt engineering playing a key role in mitigating attacks.
- The chapter highlights the importance of providing models with not just instructions but also relevant context to accomplish tasks effectively.
- The provided table details message types and privilege levels in conversational AI systems, offering guidelines for creating effective prompts while maintaining security.
- The chapter concludes with insights into the evolving nature of AI security and the continuous need for innovative defense mechanisms.

## code snippets
```
No direct code references found in the chapter.
prompts.py
GPT4o_ENTITY_EXTRACTION_PROMPT
from prompts import GPT4o_ENTITY_EXTRACTION_PROMPT
def query_openai(model_name, user_prompt):
from pydantic import BaseModel
class Prompt(BaseModel):
```
