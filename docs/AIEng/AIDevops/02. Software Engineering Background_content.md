---
sidebar_position: 1
tags: ["Distributed Computing", "Virtual Machines", "Containers", "Microservice Architecture", "DevOps", "REST", "GraphQL", "Infrastructure as Code", "MLOps"]
title: "02. Software Engineering Background"
---

## summary

- The chapter emphasizes the importance of a solid foundation in distributed computing, DevOps, and MLOps for AI engineering.
- Distributed computing is highlighted as essential for AI systems due to their need for substantial computational resources and efficient data handling, with a focus on cloud environments.
- Virtual Machines (VMs) and containers are discussed as key virtualization technologies, with containers offering advantages in terms of isolation, image transfer time, and startup time.
- The chapter explains the role of messaging in distributed systems, detailing how messages are layered and transmitted across networks using protocols like TCP/IP.
- Autoscaling in cloud environments is presented as a critical feature for managing computational load, with rules to dynamically adjust resources based on demand.
- Discovery mechanisms for services, whether packaged as VMs or containers, are explored, including the use of DNS for VMs and container orchestration for containers.
- Container orchestration is likened to conducting an orchestra, managing the life cycle of containers including provisioning, deployment, discovery, scaling, and load balancing.
- Three distributed software architectures are discussed: client-server, service-oriented (SOA), and microservice, each with implications for AI systems in terms of model training, deployment, and system design.
- The client-server architecture is noted for its simplicity and effectiveness but potential bottlenecks in scalability and resilience for complex AI systems.
- SOA is highlighted for its modular approach, allowing AI capabilities to be integrated as services within enterprise systems, supporting interoperability and efficiency.
- Microservice architecture is presented as highly scalable and flexible, suitable for complex, distributed AI systems, with services designed to be independently deployable and scalable.
- The chapter includes detailed descriptions of images illustrating virtualization technologies and containerized application deployment, enhancing understanding of these concepts.
- Practical implementation opportunities are flagged, such as packaging ML models for execution in containers and leveraging autoscaling for AI model deployment.
- The discussion on architectural styles provides insights into designing AI systems that are scalable, resilient, and capable of integrating with existing enterprise systems.
- Microservices architecture is critiqued for its maintenance complexity due to the operational overhead of managing numerous small services.
- REST and GraphQL are highlighted as the two most commonly used interface styles in todayâ€™s AI-based systems, with REST being synonymous with HTTP/1.1 for its stateless, resource-centered approach.
- GraphQL is introduced as a solution for mobile applications with limited bandwidth, allowing clients to define the structure of the requested data, thus reducing unnecessary data transfer.
- DevOps practices are described as a means to resolve the contradiction between developers' and operators' goals through cultural, organizational, and technological strategies, including automation and Infrastructure as Code (IaC).
- IaC is emphasized for its role in preventing inconsistencies among development, test, and production environments, with best practices including version control, security scanning, and testing.
- The benefits of IaC include decreased costs for repetitive tasks, reduced input errors, and improved reliability and traceability, though it comes with initial development and complexity costs.
- Idempotence in IaC scripts is discussed as a desirable property, ensuring that scripts yield the same result regardless of the infrastructure's current state.
- Infrastructure drift is identified as a common problem where the actual infrastructure state diverges from the IaC specification, potentially leading to security issues.
- DevOps processes are outlined, starting with design and initialization, through development, building, testing, release, operation, and monitoring, emphasizing the importance of quality gates.
- MLOps is introduced as applying DevOps principles to the machine learning lifecycle, focusing on data governance and the integration of ML into production systems.
- The chapter includes descriptions of images illustrating the DevOps processes and the software development lifecycle, enhancing understanding of these concepts.
- Practical implementation opportunities are flagged, such as the use of REST and GraphQL for AI model integration and the application of IaC for environment consistency.
- The discussion on DevOps and MLOps provides insights into designing scalable, reliable systems and the importance of automation and version control in modern software engineering.
- MLOps is introduced with distinctive practices including data versioning, experiment tracking, lineage tracking, model versioning, training and retraining, deployment, and performance monitoring to strengthen links between data scientists, ML engineers, and operations teams.
- A contentious issue within MLOps is the dynamic updating of models in production, with debates on ensuring model responsiveness versus compromising quality.
- MLOps is geared towards settings where a model is trained based on organization-available data, with considerations for generative AI and foundation models (FMs) highlighting the need for MLOps practices in fine-tuning FMs for specific applications.
- The chapter emphasizes the importance of considering both AI and non-AI parts in the behavior of AI systems, suggesting MLOps may suffice for AI components but a broader perspective is necessary.
- Distributed computing is summarized as the basis of modern environments like the cloud, with components packaged as VMs or containers communicating via messages and utilizing discovery mechanisms for scaling.
- Common software architectures for distributed systems include client-server, service-oriented, and microservices architectures, with REST and GraphQL highlighted as interface styles reducing communication costs, especially for edge devices.
- Traditional DevOps and MLOps are presented as complementary processes for managing development, deployment, and operations, both utilizing Infrastructure as Code (IaC) for repeatable and consistent practices.
- The focus of the book is stated to be on AI engineering and the integration of MLOps into DevOps for the whole system, beyond just the AI components.
- Discussion questions and further reading suggestions are provided to explore topics like transfer times for VMs and containers, microservices architectures, MLFlow tools, and foundational texts on REST and MLOps.
- The chapter includes an image description of a cyclical software engineering process centered around an AI model, emphasizing continuous improvement through design, develop, deploy, operate and monitor, and analyze phases.

## code snippets
```
No direct code references found in the chapter.
```
