---
sidebar_position: 1
tags: ["Efficiency", "Accuracy", "Latency", "Scalability", "Resource Utilization", "Classification Models", "Regression Models", "Foundation Models", "Adversarial Testing"]
title: "08. Performance"
---

## summary

- Performance in software engineering and AI is discussed with a focus on computation efficiency and model accuracy, highlighting the inherent tradeoffs between them.
- Efficiency is defined in terms of throughput, latency, scalability, and resource utilization, with specific applications to AI systems like LLM APIs.
- The chapter introduces fundamental concepts of efficiency, including throughput as the system's capacity to process tasks, and latency as the response time for a single task.
- Scalability is explained in the context of AI systems, distinguishing between training and inference scalability.
- Resource utilization is detailed for both training and inference phases, emphasizing the significant computational demands of training complex models like LLMs.
- Approaches to improving efficiency are organized around the system's lifecycle, starting with architecture design techniques to reduce network latency.
- Model development considerations include choosing less complex models for resource efficiency and the trend towards small language models (SLMs).
- Hyperparameter tuning and model preparation techniques are discussed as methods to reduce resource requirements and improve efficiency.
- Operation techniques for improving efficiency involve parallelism, batching, and the use of monitoring data for alerts, scaling, and reallocation.
- The chapter concludes with a discussion on the efficiency considerations of foundation models (FMs), including computational cost, inference speed, and energy consumption.
- Accuracy in AI is defined as the quality of the model's output, with a distinction made between the broad concept of accuracy and the specific metric of accuracy rate.
- The provided figure (Figure 8.1) categorizes performance metrics in AI engineering, highlighting efficiency and scalability as key components.
- The chapter delves into the metrics for evaluating the accuracy of classification and regression models, including precision, recall, F1 score, MSE, RMSE, MAE, and R-squared.
- Foundation Models (FMs) present unique challenges in accuracy measurement due to their diverse capabilities, with benchmarks like GLUE, SuperGLUE, and MMLU being highlighted for assessment.
- Repeatability in AI systems is discussed, noting the inherent nondeterminism in ML algorithms and the desirability of variability in certain applications.
- Approaches to improving accuracy are outlined, focusing on architecture design, hyperparameter tuning, data preparation, and model generation.
- Data preparation emphasizes the importance of representative and unbiased training data, handling missing data and outliers, and the strategic splitting of data into training, validation, and test sets.
- Model preparation techniques include feature scaling, categorical data conversion, and feature engineering to enhance model accuracy.
- Operations phase strategies for maintaining accuracy involve periodic testing, visualization tools like confusion matrices, and statistical tests for data drift detection.
- FM-based systems face accuracy challenges due to their scale and domain-independent nature, with solutions like fine-tuning, RAG, and RLHF being proposed.
- Adversarial testing and human evaluation are introduced as methods to assess and improve the robustness and accuracy of FMs.
- Benchmarks and domain-specific evaluations are crucial for measuring the accuracy of FMs in specialized fields.
- Acceptance testing and the creation of high-quality test cases are emphasized for ensuring the ethical and accurate performance of AI systems.
- The chapter concludes with a summary on the dual aspects of performance in AI systems—efficiency and accuracy—and the importance of monitoring and simple model use for simple problems.
- Discussion questions and further reading suggestions are provided to deepen understanding of performance tradeoffs and optimization strategies in AI systems.

## code snippets
```

```
